# ======================================================================================
# ê°œì¸í™”ëœ í˜œíƒ ì¶”ì²œ RAG ì‹œìŠ¤í…œ + Perplexity API ì—°ë™
# ======================================================================================

import json
import requests
import chromadb
import os
import sys
import re
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple, Set
import math
from collections import defaultdict

# ê¸°ì¡´ ëª¨ë“ˆ import
from multi_category_parser import MultiCategoryQueryParser
from multi_category_dummy_data import MULTI_CATEGORY_DATA

# ğŸ”§ ì‚¬ìš©ì ì´ë ¥ ëª¨ë“ˆ import (ë‹¨ìˆœ ë¶„ë¦¬)
from user_history_data import create_sample_user_history


class PerplexityAPI:
    """Perplexity API í´ë˜ìŠ¤ (ë‘ë²ˆì§¸ ì½”ë“œì—ì„œ ê°€ì ¸ì˜´)"""
    def __init__(self, api_key=None):
        self.base_url = "https://api.perplexity.ai/chat/completions"
        self.api_key = api_key or self.get_api_key()
        
    def get_api_key(self):
        """API í‚¤ ì…ë ¥ë°›ê¸°"""
        api_key = os.getenv("PERPLEXITY_API_KEY")
        
        if not api_key:
            print("ğŸ’¡ Perplexity API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
            print("1. https://www.perplexity.ai/settings/api ì—ì„œ API í‚¤ ìƒì„±")
            print("2. Pro êµ¬ë…ìëŠ” ë§¤ì›” $5 í¬ë ˆë”§ ë¬´ë£Œ ì œê³µ")
            api_key = input("\nğŸ”‘ Perplexity API í‚¤: ").strip()
        
        return api_key
    
    def search(self, query, model="sonar", max_tokens=2000):
        """ì‹¤ì‹œê°„ ê²€ìƒ‰ ìˆ˜í–‰"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤
        models = {
            "sonar": "sonar",
            "sonar-pro": "sonar-pro",
            "online": "llama-3.1-sonar-large-128k-online",
            "chat": "llama-3.1-sonar-large-128k-chat"
        }
        
        data = {
            "model": models.get(model, "sonar"),
            "messages": [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì‹¤ì‹œê°„ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” AIì…ë‹ˆë‹¤. ìµœì‹  ì •ë³´ë¥¼ ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ì œê³µí•˜ê³ , ê°€ëŠ¥í•œ ê²½ìš° ì¶œì²˜ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user", 
                    "content": query
                }
            ],
            "max_tokens": max_tokens,
            "temperature": 0.2,
            "return_citations": True
        }
        
        try:
            response = requests.post(self.base_url, headers=headers, json=data)
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                
                return {
                    'success': True,
                    'content': content,
                    'usage': result.get('usage', {}),
                    'model': models.get(model, "sonar")
                }
            else:
                return {
                    'success': False,
                    'error': f"API ì˜¤ë¥˜ {response.status_code}: {response.text}"
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f"ìš”ì²­ ì˜¤ë¥˜: {str(e)}"
            }


class PersonalizedScoreCalculator:
    """ê°œì¸í™” ìŠ¤ì½”ì–´ ê³„ì‚°ê¸°"""
    
    @staticmethod
    def calculate_preference_score(brand: str, category: str, user_history: Dict) -> float:
        """ê°œì¸ ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° (0-1)"""
        brand_count = user_history.get('brand_counts', {}).get(brand, 0)
        category_count = user_history.get('category_counts', {}).get(category, 0) 
        total_transactions = user_history.get('total_transactions', 1)
        
        # ë¸Œëœë“œ ì„ í˜¸ë„ (ê°€ì¤‘ì¹˜ 70%)
        brand_preference = brand_count / total_transactions if total_transactions > 0 else 0
        
        # ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„ (ê°€ì¤‘ì¹˜ 30%)
        category_preference = category_count / total_transactions if total_transactions > 0 else 0
        
        return (brand_preference * 0.7) + (category_preference * 0.3)
    
    @staticmethod
    def calculate_potential_savings(benefit_type: str, discount_rate: float, 
                                  user_avg_spending: float) -> float:
        """ì˜ˆìƒ ì ˆê°ì•¡ ê³„ì‚° (ì› ë‹¨ìœ„)"""
        if benefit_type == "í• ì¸":
            return user_avg_spending * (discount_rate / 100)
        elif benefit_type == "ì ë¦½":
            return user_avg_spending * (discount_rate / 100) * 0.5  # ì ë¦½ì€ í• ì¸ì˜ 50% ê°€ì¹˜
        elif benefit_type == "ì¦ì •":
            return user_avg_spending * 0.2  # ì¦ì •í’ˆ ê°€ì¹˜ë¥¼ í‰ê·  ì†Œë¹„ì˜ 20%ë¡œ ê°€ì •
        else:
            return user_avg_spending * 0.1  # ê¸°íƒ€ í˜œíƒ
    
    @staticmethod
    def calculate_recency_weight(spending_date: datetime, current_date: datetime) -> float:
        """ìµœê·¼ì„± ê°€ì¤‘ì¹˜ ê³„ì‚° (0-1)"""
        days_diff = (current_date - spending_date).days
        if days_diff <= 7:
            return 1.0
        elif days_diff <= 30:
            return 0.8
        elif days_diff <= 90:
            return 0.5
        else:
            return 0.2


class PersonalizedBenefitRAG:
    """ê°œì¸í™”ëœ í˜œíƒ ì¶”ì²œ RAG ì‹œìŠ¤í…œ (ë¸Œëœë“œ ì¸ì‹ ë° ê°œì¸í™” ìš”ì²­ ì²˜ë¦¬ ê°œì„ )"""
    
    def __init__(self, db_path="./cafe_vector_db", collection_name="cafe_benefits"):
        self.db_path = db_path
        self.collection_name = collection_name
        self.client = None
        self.collection = None
        self.score_calculator = PersonalizedScoreCalculator()
        self.vector_space_type = "unknown"  # DBì—ì„œ ìë™ ê°ì§€
        
        # ğŸ” DB ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬ ìºì‹œ
        self.available_brands: Set[str] = set()
        self.available_categories: Set[str] = set()
        self.db_metadata_loaded = False
        
        # ğŸ”— Perplexity API ì¶”ê°€
        self.perplexity_api = None
        self._init_perplexity_api()
        
        # API ì‹¤í–‰ì ì´ˆê¸°í™”
        api_key = 'Bearer nv-53f7a8c4abe74e20ab90446ed46ba79fvozJ'
        
        self.embedding_executor = EmbeddingExecutor(
            host='clovastudio.stream.ntruss.com',
            api_key=api_key,
            request_id='93ae6593a47d4437b634f2cbc5282896'
        )
        
        self.completion_executor = CompletionExecutor(
            host="https://clovastudio.stream.ntruss.com",
            api_key=api_key,
            request_id='a8a2aebe279a445f8425e0e2aa8c118d'
        )

    def _init_perplexity_api(self):
        """ğŸ”— Perplexity API ì´ˆê¸°í™”"""
        try:
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ í™•ì¸
            api_key = os.getenv("PERPLEXITY_API_KEY")
            if api_key:
                self.perplexity_api = PerplexityAPI(api_key)
                print("ğŸ”— Perplexity API ì—°ê²° ì„±ê³µ")
            else:
                print("ğŸ’¡ Perplexity API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ PERPLEXITY_API_KEY ì„¤ì •í•˜ê±°ë‚˜ ë‚˜ì¤‘ì— ì…ë ¥í•˜ì„¸ìš”.")
        except Exception as e:
            print(f"âš ï¸ Perplexity API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.perplexity_api = None

    def _search_with_perplexity(self, query: str, brand: str = None) -> str:
        """ğŸ”— Perplexity APIë¡œ ì‹¤ì‹œê°„ ê²€ìƒ‰"""
        try:
            # APIê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™” ì‹œë„
            if not self.perplexity_api:
                try:
                    self.perplexity_api = PerplexityAPI()
                except:
                    return "âŒ Perplexity APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
            
            # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
            if brand:
                search_query = f"2025ë…„ 8ì›” í˜„ì¬ {brand} í• ì¸ í˜œíƒ ì´ë²¤íŠ¸ í”„ë¡œëª¨ì…˜ ì¿ í°"
            else:
                search_query = f"2025ë…„ 8ì›” í˜„ì¬ {query} í• ì¸ í˜œíƒ ì´ë²¤íŠ¸ í”„ë¡œëª¨ì…˜"
            
            print(f"ğŸ” Perplexity ê²€ìƒ‰ ì¤‘: {search_query}")
            
            # ì‹¤ì‹œê°„ ê²€ìƒ‰ ìˆ˜í–‰
            result = self.perplexity_api.search(search_query, model="sonar")  # sonar-pro ëŒ€ì‹  sonar ì‚¬ìš©
            
            if result['success']:
                content = result['content']
                
                # ê²°ê³¼ í¬ë§·íŒ…
                response = f"ğŸŒ ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼ (Perplexity):\n\n"
                response += content
                
                return response
            else:
                return f"âŒ ì‹¤ì‹œê°„ ê²€ìƒ‰ ì‹¤íŒ¨: {result['error']}"
                
        except Exception as e:
            return f"âŒ ì‹¤ì‹œê°„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}"

    def _extract_categories_from_query(self, query: str, debug: bool = False) -> List[str]:
        """ğŸ”§ ì¿¼ë¦¬ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
        
        if debug:
            print(f"ğŸ” ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ì‹œì‘: '{query}'")
        
        found_categories = []
        
        # í™•ì‹¤í•œ ì¹´í…Œê³ ë¦¬ íŒ¨í„´ ë§¤ì¹­
        known_category_patterns = {
            'ì¹´í˜': [r'ì¹´í˜', r'ì»¤í”¼', r'coffee', r'cafe', r'ì»¤í”¼ìˆ', r'ì»¤í”¼ì ', r'ì•„ë©”ë¦¬ì¹´ë…¸', r'ë¼ë–¼'],
            'ë§ˆíŠ¸': [r'ë§ˆíŠ¸', r'mart', r'ìŠˆí¼', r'ëŒ€í˜•ë§ˆíŠ¸', r'í• ì¸ë§ˆíŠ¸', r'ì‡¼í•‘ëª°', r'ìƒí•„í’ˆ'],
            'í¸ì˜ì ': [r'í¸ì˜ì ', r'í¸ì˜', r'ì»¨ë¹„ë‹ˆ', r'convenience'],
            'ì˜¨ë¼ì¸ì‡¼í•‘': [r'ì˜¨ë¼ì¸', r'ì‡¼í•‘', r'ì¸í„°ë„·', r'online', r'shopping', r'ì´ì»¤ë¨¸ìŠ¤', r'ë°°ì†¡'],
            'ì‹ë‹¹': [r'ì‹ë‹¹', r'ìŒì‹ì ', r'ë ˆìŠ¤í† ë‘', r'restaurant', r'ìŒì‹', r'ë¨¹ê±°ë¦¬', r'dining', r'ì¹˜í‚¨', r'ë²„ê±°', r'í–„ë²„ê±°'],
            'ë·°í‹°': [r'ë·°í‹°', r'í™”ì¥í’ˆ', r'ë¯¸ìš©', r'beauty', r'cosmetic', r'ìŠ¤í‚¨ì¼€ì–´', r'ë©”ì´í¬ì—…'],
            'ì˜ë£Œ': [r'ì˜ë£Œ', r'ì•½êµ­', r'ë³‘ì›', r'pharmacy', r'medical', r'health', r'ê±´ê°•', r'ì˜ì–‘ì œ', r'ë¹„íƒ€ë¯¼'],
            'êµí†µ': [r'êµí†µ', r'ì§€í•˜ì² ', r'ë²„ìŠ¤', r'íƒì‹œ', r'ì „ì² ', r'ëŒ€ì¤‘êµí†µ', r'metro', r'ì •ê¸°ê¶Œ']
        }
        
        query_lower = query.lower()
        
        # í™•ì‹¤í•œ ì¹´í…Œê³ ë¦¬ íŒ¨í„´ ë§¤ì¹­
        for category_name, patterns in known_category_patterns.items():
            for pattern in patterns:
                if re.search(pattern, query_lower, re.IGNORECASE):
                    found_categories.append(category_name)
                    if debug:
                        print(f"   âœ… ì¹´í…Œê³ ë¦¬ ë°œê²¬: '{category_name}' (íŒ¨í„´: {pattern})")
                    break
        
        # ì¤‘ë³µ ì œê±°
        unique_categories = list(set(found_categories))
        
        if debug:
            print(f"   ğŸ¯ ìµœì¢… ì¶”ì¶œëœ ì¹´í…Œê³ ë¦¬: {unique_categories}")
        
        return unique_categories

    def _try_direct_category_search(self, query: str, categories: List[str], top_k: int, debug: bool = False) -> List[Dict]:
        """ğŸ¯ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì§ì ‘ ê²€ìƒ‰ (ê°„ë‹¨ ë²„ì „)"""
        try:
            if debug:
                print(f"ğŸ¯ ì§ì ‘ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ì‹œë„: {categories}")
            
            all_results = []
            
            for category in categories:
                try:
                    category_results = self.collection.get(
                        where={"category": {"$eq": category}},
                        include=["metadatas", "documents"]
                    )
                    
                    if category_results and category_results.get('metadatas'):
                        for i, metadata in enumerate(category_results['metadatas']):
                            # ìœ íš¨ì„± ê²€ì¦
                            if self._validate_result(metadata, datetime.now()):
                                all_results.append({
                                    "id": f"direct_cat_{category}_{i}",
                                    "metadata": metadata,
                                    "distance": 0.0,  # ì§ì ‘ ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ì´ë¯€ë¡œ ìµœê³  ì ìˆ˜
                                    "document": category_results['documents'][i] if category_results.get('documents') else "",
                                    "vector_rank": i + 1
                                })
                    
                    if debug:
                        count = len(category_results['metadatas']) if category_results and category_results.get('metadatas') else 0
                        print(f"   '{category}': {count}ê°œ ê²°ê³¼")
                        
                except Exception as e:
                    if debug:
                        print(f"   '{category}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue
            
            # ê²°ê³¼ ì œí•œ
            if all_results:
                limited_results = all_results[:top_k]
                if debug:
                    print(f"ğŸ¯ ì§ì ‘ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ì„±ê³µ: {len(limited_results)}ê°œ ë°˜í™˜")
                return limited_results
            
            return []
            
        except Exception as e:
            if debug:
                print(f"âŒ ì§ì ‘ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    def calculate_vector_similarity_universal(self, distance: float, all_distances: List[float] = None) -> float:
        """ğŸ”§ ë§ŒëŠ¥ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚° (ìŒìˆ˜ ê±°ë¦¬ê°’ ì²˜ë¦¬)"""
        
        # ìŒìˆ˜ ê±°ë¦¬ê°’ ì²˜ë¦¬ (IP ë°©ì‹)
        if distance < 0:
            # Inner Product: ìŒìˆ˜ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ
            # -800ëŒ€ ê°’ì„ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            if all_distances:
                min_dist = min(all_distances)
                max_dist = max(all_distances)
                range_dist = max_dist - min_dist
                
                if range_dist > 0:
                    # ìƒëŒ€ì  ìœ„ì¹˜ ê³„ì‚° (IPëŠ” ë†’ì„ìˆ˜ë¡ ìœ ì‚¬í•˜ë¯€ë¡œ ì—­ì „)
                    relative_pos = (distance - min_dist) / range_dist
                    similarity = 1 - relative_pos  # ë†’ì€ ê°’ = ë†’ì€ ìœ ì‚¬ë„
                else:
                    similarity = 0.5  # ëª¨ë‘ ë™ì¼í•˜ë©´ ì¤‘ê°„ê°’
            else:
                # ë‹¨ìˆœ ì •ê·œí™” (-1000 ~ -800 ë²”ìœ„ ê°€ì •)
                normalized = max(0, min(1, (distance + 1000) / 200))
                similarity = normalized
        
        # ì–‘ìˆ˜ ê±°ë¦¬ê°’ ì²˜ë¦¬ (cosine/l2 ë°©ì‹)
        else:
            if self.vector_space_type == "cosine":
                # Cosine ê±°ë¦¬: 0=ì¼ì¹˜, 2=ë°˜ëŒ€
                similarity = max(0, 1 - (distance / 2))
            elif self.vector_space_type == "l2":
                # L2 ê±°ë¦¬: 0=ì¼ì¹˜, sqrt(2)=ìµœëŒ€ (ì •ê·œí™”ëœ ë²¡í„°)
                similarity = max(0, 1 - (distance / 1.414))
            else:
                # ê¸°ë³¸ê°’
                similarity = max(0, 1 - distance)
        
        return max(0, min(similarity, 1))  # 0-1 ë²”ìœ„ ë³´ì¥
    
    def connect_database(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (ì½ê¸° ì „ìš©)"""
        try:
            if not os.path.exists(self.db_path):
                print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤: {self.db_path}")
                return False
            
            self.client = chromadb.PersistentClient(path=self.db_path)
            
            # ğŸ” ëª¨ë“  ì»¬ë ‰ì…˜ ì´ë¦„ í™•ì¸
            try:
                collections = self.client.list_collections()
                print(f"ğŸ” ë°œê²¬ëœ ì»¬ë ‰ì…˜ë“¤: {[c.name for c in collections]}")
                
                if collections:
                    # ì²« ë²ˆì§¸ ì»¬ë ‰ì…˜ ì‚¬ìš©
                    self.collection = collections[0]
                    self.collection_name = collections[0].name
                    print(f"âœ… ìë™ ì„ íƒëœ ì»¬ë ‰ì…˜: {self.collection_name}")
                else:
                    print("âŒ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
                    return False
                    
            except Exception as e:
                # ê¸°ì¡´ ë°©ì‹ ì‹œë„
                print(f"ì»¬ë ‰ì…˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨, ê¸°ë³¸ ì´ë¦„ìœ¼ë¡œ ì‹œë„: {e}")
                self.collection = self.client.get_collection(name=self.collection_name)
            
            # ë²¡í„° ê³µê°„ íƒ€ì… ê°ì§€
            metadata = self.collection.metadata
            self.vector_space_type = metadata.get("hnsw:space", "unknown")
            
            count = self.collection.count()
            print(f"âœ… RAG DB ì—°ê²° ì„±ê³µ (ì´ {count}ê°œ ë¬¸ì„œ, {self.vector_space_type.upper()} ê±°ë¦¬)")
            print("ğŸ”’ ì½ê¸° ì „ìš© ëª¨ë“œ - DB ìˆ˜ì •í•˜ì§€ ì•ŠìŒ")
            
            # ğŸ” DB ë©”íƒ€ë°ì´í„° ë¡œë“œ
            self._load_database_metadata()
            
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def _load_database_metadata(self) -> None:
        """ğŸ” DBì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬ ëª©ë¡ ë¡œë“œ"""
        try:
            print("ğŸ” DB ë©”íƒ€ë°ì´í„° ë¡œë”© ì¤‘...")
            
            # ëª¨ë“  ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ (ë²¡í„° ì—†ì´)
            all_results = self.collection.get(
                include=["metadatas"]
            )
            
            if not all_results or not all_results.get('metadatas'):
                print("âŒ DB ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
                return
            
            # ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
            for metadata in all_results['metadatas']:
                if metadata:
                    brand = metadata.get('brand')
                    category = metadata.get('category')
                    
                    if brand:
                        self.available_brands.add(brand.strip())
                    if category:
                        self.available_categories.add(category.strip())
            
            self.db_metadata_loaded = True
            
            print(f"âœ… DB ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
            print(f"   ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ ë¸Œëœë“œ: {len(self.available_brands)}ê°œ")
            print(f"   ğŸ·ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬: {len(self.available_categories)}ê°œ")
            
            # ì£¼ìš” ë¸Œëœë“œ ë¯¸ë¦¬ë³´ê¸°
            if self.available_brands:
                sample_brands = list(self.available_brands)[:10]
                print(f"   ğŸ” ë¸Œëœë“œ ì˜ˆì‹œ: {', '.join(sample_brands)}")
            
        except Exception as e:
            print(f"âŒ DB ë©”íƒ€ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            self.db_metadata_loaded = False
    
    def _check_brand_existence(self, brands: List[str], debug: bool = False) -> Dict[str, bool]:
        """ğŸ” ë¸Œëœë“œê°€ DBì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        if not self.db_metadata_loaded:
            if debug:
                print("âš ï¸ DB ë©”íƒ€ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ - ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë¶ˆê°€")
            return {brand: True for brand in brands}  # ì•ˆì „í•˜ê²Œ í†µê³¼
        
        result = {}
        for brand in brands:
            # ì •í™•í•œ ë§¤ì¹­
            exact_match = brand in self.available_brands
            
            # ìœ ì‚¬í•œ ë¸Œëœë“œ ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ, ë¶€ë¶„ ë§¤ì¹­)
            similar_match = any(
                brand.lower() in available_brand.lower() or 
                available_brand.lower() in brand.lower()
                for available_brand in self.available_brands
            )
            
            exists = exact_match or similar_match
            result[brand] = exists
            
            if debug:
                status = "âœ… ì¡´ì¬" if exists else "âŒ ì—†ìŒ"
                print(f"   ğŸ” '{brand}': {status}")
        
        return result
    
    def _check_category_existence(self, categories: List[str], debug: bool = False) -> Dict[str, bool]:
        """ğŸ” ì¹´í…Œê³ ë¦¬ê°€ DBì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        if not self.db_metadata_loaded:
            if debug:
                print("âš ï¸ DB ë©”íƒ€ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ - ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë¶ˆê°€")
            return {category: True for category in categories}  # ì•ˆì „í•˜ê²Œ í†µê³¼
        
        result = {}
        for category in categories:
            # ì •í™•í•œ ë§¤ì¹­
            exact_match = category in self.available_categories
            
            # ìœ ì‚¬í•œ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
            similar_match = any(
                category.lower() in available_category.lower() or 
                available_category.lower() in category.lower()
                for available_category in self.available_categories
            )
            
            exists = exact_match or similar_match
            result[category] = exists
            
            if debug:
                status = "âœ… ì¡´ì¬" if exists else "âŒ ì—†ìŒ"
                print(f"   ğŸ” '{category}': {status}")
        
        return result
    
    def create_user_profile(self, user_spending_history: List[Dict]) -> Dict:
        """ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±"""
        profile = {
            'brand_counts': defaultdict(int),
            'category_counts': defaultdict(int),
            'brand_spending': defaultdict(float),
            'category_spending': defaultdict(float),
            'total_transactions': 0,
            'total_spending': 0.0,
            'recent_brands': [],  # ìµœê·¼ 1ì£¼ì¼
            'preferred_categories': [],
            'avg_spending_per_brand': {},
            'spending_timeline': []
        }
        
        current_date = datetime.now()
        recent_threshold = current_date - timedelta(days=7)
        
        for transaction in user_spending_history:
            brand = transaction['brand']
            category = transaction.get('category', 'Unknown')
            amount = transaction['amount']
            date = datetime.fromisoformat(transaction['date']) if isinstance(transaction['date'], str) else transaction['date']
            
            # ê¸°ë³¸ í†µê³„
            profile['brand_counts'][brand] += 1
            profile['category_counts'][category] += 1
            profile['brand_spending'][brand] += amount
            profile['category_spending'][category] += amount
            profile['total_transactions'] += 1
            profile['total_spending'] += amount
            
            # ìµœê·¼ ë¸Œëœë“œ (ê°€ì¤‘ì¹˜ ì ìš©)
            if date >= recent_threshold:
                recency_weight = self.score_calculator.calculate_recency_weight(date, current_date)
                profile['recent_brands'].append({
                    'brand': brand,
                    'category': category,
                    'amount': amount,
                    'weight': recency_weight,
                    'date': date
                })
            
            # ì‹œê°„ìˆœ ê¸°ë¡
            profile['spending_timeline'].append({
                'brand': brand,
                'category': category, 
                'amount': amount,
                'date': date
            })
        
        # ë¸Œëœë“œë³„ í‰ê·  ì†Œë¹„ì•¡ ê³„ì‚°
        for brand, total_amount in profile['brand_spending'].items():
            count = profile['brand_counts'][brand]
            profile['avg_spending_per_brand'][brand] = total_amount / count
        
        # ì„ í˜¸ ì¹´í…Œê³ ë¦¬ ì •ë ¬ (ì†Œë¹„ ë¹ˆë„ ê¸°ì¤€)
        profile['preferred_categories'] = sorted(
            profile['category_counts'].items(), 
            key=lambda x: x[1], 
            reverse=True
        )
        
        return dict(profile)  # defaultdictë¥¼ ì¼ë°˜ dictë¡œ ë³€í™˜

    def _is_personalization_query(self, query: str) -> bool:
        """ğŸ¯ ê°œì¸í™” ìš”ì²­ì¸ì§€ íŒë‹¨"""
        personalization_patterns = [
            # ëª…ì‹œì  ê°œì¸í™” ìš”ì²­
            r'ë‚´\s*ì†Œë¹„.*íŒ¨í„´', r'ë‚´.*ë§ëŠ”', r'ë‚˜.*ë§ëŠ”', r'ìš°ë¦¬.*ë§ëŠ”',
            r'ê°œì¸í™”.*ì¶”ì²œ', r'ë§ì¶¤.*ì¶”ì²œ', r'ë§ì¶¤í˜•.*í˜œíƒ',
            
            # ì†Œë¹„ ì´ë ¥ ê¸°ë°˜ ìš”ì²­
            r'ì§€ë‚œ.*ì†Œë¹„', r'ìµœê·¼.*ì†Œë¹„', r'ì €ë²ˆ.*ì†Œë¹„',
            r'ì§€ë‚œì£¼.*ì¼', r'ì €ë²ˆì£¼.*ì¼', r'ìµœê·¼.*ì¼',
            r'ë‚´ê°€.*ìì£¼', r'ë‚´ê°€.*ë§ì´', r'ë‚´ê°€.*ì£¼ë¡œ',
            
            # ì¼ë°˜ì ì¸ ì¶”ì²œ ìš”ì²­ (ë¸Œëœë“œ ì—†ì´)
            r'^(?!.*[ê°€-í£A-Za-z]{2,}\s*(í˜œíƒ|ì´ë²¤íŠ¸|í• ì¸)).*ì¶”ì²œ.*í•´.*ì¤˜',
            r'^(?!.*[ê°€-í£A-Za-z]{2,}\s*(í˜œíƒ|ì´ë²¤íŠ¸|í• ì¸)).*í˜œíƒ.*ìˆ.*ì–´',
            
            # íŒ¨í„´ ê¸°ë°˜ ìš”ì²­
            r'íŒ¨í„´.*ê¸°ë°˜', r'ì´ë ¥.*ê¸°ë°˜', r'íˆìŠ¤í† ë¦¬.*ê¸°ë°˜'
        ]
        
        for pattern in personalization_patterns:
            if re.search(pattern, query, re.IGNORECASE):
                return True
        
        return False
    def _try_direct_brand_search(self, query: str, top_k: int, debug: bool = False) -> List[Dict]:
        """ğŸ¯ ë¸Œëœë“œ ê¸°ë°˜ ì§ì ‘ ê²€ìƒ‰ (ë²¡í„° ê²€ìƒ‰ ì „ì— ì‹œë„)"""
        try:
            # ì¿¼ë¦¬ì—ì„œ ë¸Œëœë“œ ì¶”ì¶œ
            extracted_brands = self._extract_brands_from_query(query, debug)
            
            if not extracted_brands:
                return []
            
            if debug:
                print(f"ğŸ¯ ì§ì ‘ ë¸Œëœë“œ ê²€ìƒ‰ ì‹œë„: {extracted_brands}")
            
            # ê° ë¸Œëœë“œë³„ë¡œ ì§ì ‘ ê²€ìƒ‰
            all_results = []
            
            for brand in extracted_brands:
                # DBì—ì„œ í•´ë‹¹ ë¸Œëœë“œ ì§ì ‘ ì°¾ê¸°
                try:
                    brand_results = self.collection.get(
                        where={"brand": {"$eq": brand}},
                        include=["metadatas", "documents"]
                    )
                    
                    if brand_results and brand_results.get('metadatas'):
                        for i, metadata in enumerate(brand_results['metadatas']):
                            # ìœ íš¨ì„± ê²€ì¦
                            if self._validate_result(metadata, datetime.now()):
                                all_results.append({
                                    "id": f"direct_{brand}_{i}",
                                    "metadata": metadata,
                                    "distance": 0.0,  # ì§ì ‘ ë§¤ì¹­ì´ë¯€ë¡œ ìµœê³  ì ìˆ˜
                                    "document": brand_results['documents'][i] if brand_results.get('documents') else "",
                                    "vector_rank": i + 1
                                })
                    
                    if debug:
                        count = len(brand_results['metadatas']) if brand_results and brand_results.get('metadatas') else 0
                        print(f"   '{brand}': {count}ê°œ ê²°ê³¼")
                        
                except Exception as e:
                    if debug:
                        print(f"   '{brand}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue
            
            # ê²°ê³¼ ì œí•œ
            if all_results:
                limited_results = all_results[:top_k]
                if debug:
                    print(f"ğŸ¯ ì§ì ‘ ë¸Œëœë“œ ê²€ìƒ‰ ì„±ê³µ: {len(limited_results)}ê°œ ë°˜í™˜")
                return limited_results
            
            return []
            
        except Exception as e:
            if debug:
                print(f"âŒ ì§ì ‘ ë¸Œëœë“œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def _fallback_text_search(self, query: str, filters: Dict, top_k: int, debug: bool = False) -> List[Dict]:
        """ğŸ”„ í…ìŠ¤íŠ¸ ê¸°ë°˜ í´ë°± ê²€ìƒ‰ (ê°œì„ ëœ ë²„ì „)"""
        try:
            if debug:
                print("ğŸ”„ í…ìŠ¤íŠ¸ í´ë°± ê²€ìƒ‰ ì‹œì‘...")
            
            # ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
            all_results = self.collection.get(
                include=["metadatas", "documents"]
            )
            
            if not all_results or not all_results.get('metadatas'):
                print("âŒ DBì— ë°ì´í„° ì—†ìŒ")
                return []
            
            # í…ìŠ¤íŠ¸ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
            scored_results = []
            query_lower = query.lower()
            query_words = query_lower.split()
            
            for i, metadata in enumerate(all_results['metadatas']):
                if not metadata:
                    continue
                
                # ìœ íš¨ì„± ê²€ì¦
                if not self._validate_result(metadata, datetime.now()):
                    continue
                
                # í…ìŠ¤íŠ¸ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
                score = 0.0
                
                # ë¸Œëœë“œ ë§¤ì¹­ (ê°€ì¥ ì¤‘ìš” - 60%)
                brand = metadata.get('brand', '').lower()
                if brand:
                    if brand in query_lower:
                        score += 0.6
                    elif any(word in brand for word in query_words):
                        score += 0.4
                    elif any(brand in word for word in query_words):
                        score += 0.3
                
                # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ (20%)
                category = metadata.get('category', '').lower()
                if category and category in query_lower:
                    score += 0.2
                
                # ì œëª© ë§¤ì¹­ (15%)
                title = metadata.get('title', '').lower()
                if title:
                    matching_words = sum(1 for word in query_words if word in title)
                    score += 0.15 * (matching_words / len(query_words))
                
                # í˜œíƒ íƒ€ì… ë§¤ì¹­ (5%)
                benefit_type = metadata.get('benefit_type', '').lower()
                benefit_keywords = ['í• ì¸', 'ì ë¦½', 'ì¿ í°', 'í˜œíƒ', 'ì´ë²¤íŠ¸', 'ì¦ì •']
                if any(keyword in query_lower for keyword in benefit_keywords):
                    if benefit_type in query_lower:
                        score += 0.05
                
                if score > 0:
                    scored_results.append({
                        "id": f"text_match_{i}",
                        "metadata": metadata,
                        "distance": 1.0 - score,  # ì ìˆ˜ë¥¼ ê±°ë¦¬ë¡œ ë³€í™˜
                        "document": all_results['documents'][i] if all_results.get('documents') else "",
                        "vector_rank": 0,
                        "text_score": score
                    })
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            scored_results.sort(key=lambda x: x['text_score'], reverse=True)
            
            # ìƒìœ„ ê²°ê³¼ë§Œ ë°˜í™˜
            final_results = scored_results[:top_k]
            
            if debug:
                print(f"ğŸ”„ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)}ê°œ ê²°ê³¼")
                for i, result in enumerate(final_results[:3]):
                    brand = result['metadata'].get('brand', 'Unknown')
                    score = result.get('text_score', 0)
                    print(f"   [{i+1}] {brand}: ì ìˆ˜ {score:.3f}")
            
            return final_results
            
        except Exception as e:
            if debug:
                print(f"âŒ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    def _extract_brands_from_query(self, query: str, debug: bool = False) -> List[str]:
        """ğŸ”§ ê°œì„ ëœ ë¸Œëœë“œ ì¶”ì¶œ (ì •í™•ë„ í–¥ìƒ)"""
        
        if debug:
            print(f"ğŸ” ë¸Œëœë“œ ì¶”ì¶œ ì‹œì‘: '{query}'")
        
        found_brands = []
        
        # 1ë‹¨ê³„: í™•ì‹¤í•œ ë¸Œëœë“œ íŒ¨í„´ ë§¤ì¹­ (í•œêµ­ ìœ ëª… ë¸Œëœë“œë“¤)
        known_brand_patterns = {
            # ì¹´í˜/ìŒì‹
            'ìŠ¤íƒ€ë²…ìŠ¤': [r'ìŠ¤íƒ€ë²…ìŠ¤', r'starbucks'],
            'ì´ë””ì•¼': [r'ì´ë””ì•¼', r'ediya'],
            'íˆ¬ì¸í”Œë ˆì´ìŠ¤': [r'íˆ¬ì¸', r'íˆ¬ì¸í”Œë ˆì´ìŠ¤', r'twosome'],
            'ë§¥ë„ë‚ ë“œ': [r'ë§¥ë„ë‚ ë“œ', r'ë§¥ë‚ ', r'mcdonald'],
            'ë²„ê±°í‚¹': [r'ë²„ê±°í‚¹', r'burgerking'],
            'KFC': [r'kfc', r'ì¼€ì´ì—í”„ì”¨'],
            
            # ë§ˆíŠ¸/ì‡¼í•‘
            'ì´ë§ˆíŠ¸': [r'ì´ë§ˆíŠ¸', r'emart'],
            'í™ˆí”ŒëŸ¬ìŠ¤': [r'í™ˆí”ŒëŸ¬ìŠ¤', r'homeplus'],
            'ë¡¯ë°ë§ˆíŠ¸': [r'ë¡¯ë°ë§ˆíŠ¸', r'lotte'],
            'ì¿ íŒ¡': [r'ì¿ íŒ¡', r'coupang'],
            'ì§€ë§ˆì¼“': [r'ì§€ë§ˆì¼“', r'gmarket'],
            '11ë²ˆê°€': [r'11ë²ˆê°€', r'ì‹­ì¼ë²ˆê°€'],
            
            # í¸ì˜ì 
            'GS25': [r'gs25', r'ì§€ì—ìŠ¤'],
            'CU': [r'cu', r'ì”¨ìœ '],
            'ì„¸ë¸ì¼ë ˆë¸': [r'ì„¸ë¸ì¼ë ˆë¸', r'7-eleven', r'ì„¸ë¸'],
            'ì´ë§ˆíŠ¸24': [r'ì´ë§ˆíŠ¸24', r'ì´ë§ˆíŠ¸ì´ì‹­ì‚¬'],
            
            # ë·°í‹°/ê¸°íƒ€
            'ì˜¬ë¦¬ë¸Œì˜': [r'ì˜¬ë¦¬ë¸Œì˜', r'oliveyoung'],
            'ë„¤ì´ë²„': [r'ë„¤ì´ë²„', r'naver'],
            'ì¹´ì¹´ì˜¤': [r'ì¹´ì¹´ì˜¤', r'kakao'],
            'ì‚¼ì„±': [r'ì‚¼ì„±', r'samsung'],
            'ì• í”Œ': [r'ì• í”Œ', r'apple'],  # ğŸ”§ ì• í”Œ ì¶”ê°€
            'LG': [r'lg', r'ì—˜ì§€'],
            'í˜„ëŒ€': [r'í˜„ëŒ€', r'hyundai']
        }
        
        query_lower = query.lower()
        
        # í™•ì‹¤í•œ ë¸Œëœë“œ íŒ¨í„´ ë§¤ì¹­
        for brand_name, patterns in known_brand_patterns.items():
            for pattern in patterns:
                if re.search(pattern, query_lower, re.IGNORECASE):
                    found_brands.append(brand_name)
                    if debug:
                        print(f"   âœ… í™•ì‹¤í•œ ë¸Œëœë“œ ë°œê²¬: '{brand_name}' (íŒ¨í„´: {pattern})")
                    break
        
        # 2ë‹¨ê³„: ğŸ”§ ë” ì—„ê²©í•œ ì¼ë°˜ ë¸Œëœë“œëª… ì¶”ì¶œ
        # í™•ì‹¤í•œ ë¸Œëœë“œê°€ ì—†ì„ ë•Œë§Œ ì¼ë°˜ ì¶”ì¶œ ì‹œë„
        if not found_brands:
            # ğŸ”§ ë¸Œëœë“œ í›„ë³´ ì¡°ê±´ì„ ë” ì—„ê²©í•˜ê²Œ
            words = query.split()
            for word in words:
                # ëª…í™•í•œ ë¸Œëœë“œëª… íŠ¹ì§•ì„ ê°€ì§„ ë‹¨ì–´ë§Œ
                if self._is_potential_brand_name(word):
                    # ğŸ”§ í™•ì¥ëœ ì¼ë°˜ ë‹¨ì–´ í•„í„°ë§
                    if not self._is_common_word(word):
                        found_brands.append(word)
                        if debug:
                            print(f"   ğŸ¤” ì ì¬ì  ë¸Œëœë“œ: '{word}'")
        
        # ì¤‘ë³µ ì œê±°
        unique_brands = list(set(found_brands))
        
        if debug:
            print(f"   ğŸ¯ ìµœì¢… ì¶”ì¶œëœ ë¸Œëœë“œ: {unique_brands}")
        
        return unique_brands

    def _is_potential_brand_name(self, word: str) -> bool:
        """ğŸ”§ ì ì¬ì  ë¸Œëœë“œëª…ì¸ì§€ íŒë‹¨ (ë” ì—„ê²©í•˜ê²Œ)"""
        # í•œê¸€ ë¸Œëœë“œ: 2-6ì (ë” ì—„ê²©í•˜ê²Œ)
        if re.match(r'^[ê°€-í£]{2,6}$', word):
            return True
        
        # ì˜ë¬¸ ë¸Œëœë“œ: ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ê±°ë‚˜ ì „ì²´ ëŒ€ë¬¸ì, 3-12ì
        if re.match(r'^[A-Z][a-zA-Z]{2,11}$', word) or re.match(r'^[A-Z]{2,8}$', word):
            return True
        
        return False

    def _is_common_word(self, word: str) -> bool:
        """ğŸ”§ ì¼ë°˜ ë‹¨ì–´ì¸ì§€ íŒë‹¨ (í™•ì¥ëœ í•„í„°ë§)"""
        common_words = {
            # ê¸°ë³¸ ë‹¨ì–´ë“¤
            'í˜œíƒ', 'í• ì¸', 'ì´ë²¤íŠ¸', 'ì¿ í°', 'ì ë¦½', 'ì¦ì •', 'ì„¸ì¼', 'íŠ¹ê°€', 'ì¶”ì²œ', 'ì°¾ì•„', 'ì•Œë ¤', 'ìˆì–´', 'í•´ì¤˜',
            
            # ì¥ì†Œ/ì¹´í…Œê³ ë¦¬
            'ì¹´í˜', 'ë§ˆíŠ¸', 'ì‹ë‹¹', 'í¸ì˜ì ', 'ì˜¨ë¼ì¸', 'ì‡¼í•‘', 'ë·°í‹°', 'ì˜ë£Œ', 'ë³‘ì›', 'ì•½êµ­', 'ì€í–‰', 'ê¸ˆìœµ',
            
            # ì„¤ëª… ë‹¨ì–´ë“¤
            'ì†Œë¹„', 'íŒ¨í„´', 'ë§ëŠ”', 'ì–´ë””', 'ë­ê°€', 'ì–´ë–¤', 'ì¢‹ì€', 'ê´œì°®ì€', 'ì €ë ´í•œ', 'ë¹„ì‹¼', 'ìµœê³ ', 'ì¸ê¸°',
            
            # ëŒ€ëª…ì‚¬/ì§€ì‹œì–´
            'ë‚´ê°€', 'ìš°ë¦¬', 'ì‚¬ëŒ', 'ê³ ê°', 'íšŒì›', 'ê°€ê²©', 'ëˆ', 'ì›', 'ë§Œì›', 'ì²œì›', 'ì •ë„', 'ì •ë§', 'ì§„ì§œ',
            
            # ë¶€ì‚¬/ì ‘ì†ì‚¬
            'ê·¸ëƒ¥', 'ì¢€', 'ì¡°ê¸ˆ', 'ë§ì´', 'ìì£¼', 'ê°€ë”', 'í•­ìƒ', 'ë³´í†µ', 'ìµœê·¼', 'ìš”ì¦˜', 'ì˜¤ëŠ˜', 'ì–´ì œ', 'ë‚´ì¼',
            
            # ì‹œê°„ ê´€ë ¨
            'ì§€ê¸ˆ', 'í˜„ì¬', 'ì´ë²ˆ', 'ë‹¤ìŒ', 'ì €ë²ˆ', 'ì˜¬í•´', 'ì‘ë…„', 'ë‚´ë…„', 'ì›”', 'ì¼', 'ì£¼', 'ë•Œë¬¸', 'ìœ„í•´',
            
            # ë™ì‚¬/í˜•ìš©ì‚¬ ì–´ê°„
            'í†µí•´', 'ëŒ€í•´', 'ê´€ë ¨', 'ê´€í•œ', 'ê°€ëŠ¥', 'ë¶ˆê°€ëŠ¥', 'í•„ìš”', 'ì¤‘ìš”', 'ìœ ìš©', 'í¸ë¦¬', 'ê°„ë‹¨', 'ë³µì¡',
            
            # ğŸ”§ ìƒˆë¡œ ì¶”ê°€ëœ í•„í„°ë§ ë‹¨ì–´ë“¤
            'ì•Œë ¤ì¤˜', 'í•´ì¤˜', 'ë³´ì—¬ì¤˜', 'ì°¾ì•„ì¤˜', 'ì¶”ì²œí•´ì¤˜', 'ë§í•´ì¤˜',
            'íŒ¨í„´ì—', 'ì†Œë¹„ì—', 'ì´ë ¥ì—', 'ê¸°ë°˜ì—', 'ë§ê²Œ', 'ë”°ë¼',
            'ì–´ë–»ê²Œ', 'ì–´ë””ì„œ', 'ì–¸ì œ', 'ì™œ', 'ë¬´ì—‡', 'ëˆ„êµ¬',
            'ìˆë‚˜', 'ìˆì–´', 'ì—†ì–´', 'ëì–´', 'ì¢‹ì•„', 'ì‹«ì–´'
        }
        
        return word in common_words
    
    def search_personalized_benefits(self, query: str, user_profile: Dict, 
                                top_k: int = 10, debug: bool = False) -> str:
        """ğŸ”— ê°œì¸í™”ëœ í˜œíƒ ê²€ìƒ‰ ë° ì¶”ì²œ (Perplexity API ì—°ë™)"""
        if debug:
            print(f"ğŸ¯ ê°œì„ ëœ ê°œì¸í™” ê²€ìƒ‰ ì‹œì‘: {query}")
            print(f"ğŸ‘¤ ì‚¬ìš©ì í”„ë¡œí•„: ì´ {user_profile['total_transactions']}ê±´, {user_profile['total_spending']:,.0f}ì›")
        
        # ğŸ”§ 1ë‹¨ê³„: ê°œì¸í™” ìš”ì²­ì¸ì§€ ë¨¼ì € í™•ì¸
        is_personalization = self._is_personalization_query(query)
        if debug:
            print(f"ğŸ¯ ê°œì¸í™” ìš”ì²­ ì—¬ë¶€: {is_personalization}")
        
        # 2ë‹¨ê³„: ì¿¼ë¦¬ ë¶„ì„
        analysis = MultiCategoryQueryParser.analyze_query_intent(query)
        filters, parsed_info = MultiCategoryQueryParser.build_multi_category_filters(query, debug)
        
        # ğŸ”§ 3ë‹¨ê³„: ê°œì„ ëœ ë¸Œëœë“œ ì¶”ì¶œ
        extracted_brands = self._extract_brands_from_query(query, debug)
        
        # ğŸ”§ 4ë‹¨ê³„: ê°œì„ ëœ ê²€ì¦ ë¡œì§ (ë” ê´€ëŒ€í•˜ê²Œ)
        validation_result = self._validate_query_improved(
            query, analysis, parsed_info, extracted_brands, is_personalization, debug
        )
        
        # ğŸ”— 4.5ë‹¨ê³„: DBì— ë¸Œëœë“œê°€ ì—†ê±°ë‚˜ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° Perplexity API ì‚¬ìš©
        if not validation_result['valid']:
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¸Œëœë“œì— ëŒ€í•œ ì‹¤ì‹œê°„ ê²€ìƒ‰
            if extracted_brands:
                brand_name = extracted_brands[0]  # ì²« ë²ˆì§¸ ë¸Œëœë“œ
                print(f"ğŸ”— DBì— '{brand_name}' ë¸Œëœë“œê°€ ì—†ì–´ ì‹¤ì‹œê°„ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤...")
                return self._search_with_perplexity(query, brand_name)
            else:
                return validation_result['message']
        
        # ğŸ”§ 5ë‹¨ê³„: ê²€ìƒ‰ ì¿¼ë¦¬ ì¤€ë¹„ (í•„í„° ì¡°ê±´ ì™„í™”)
        search_query = query
        search_filters = {}  # í•„í„° ì¡°ê±´ ì™„í™” ë˜ëŠ” ì œê±°
        
        if is_personalization and not extracted_brands:
            # ê°œì¸í™” ìš”ì²­ì´ë©´ ì‚¬ìš©ì ì„ í˜¸ ë¸Œëœë“œ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ í™•ì¥
            enhanced_query = self._enhance_query_for_personalization(query, user_profile)
            if debug:
                print(f"ğŸ¯ ê°œì¸í™” ì¿¼ë¦¬ í™•ì¥: '{enhanced_query}'")
            search_query = enhanced_query
        
        # 6ë‹¨ê³„: ê°œì„ ëœ ë²¡í„° ê²€ìƒ‰ (ì§ì ‘ ë¸Œëœë“œ ê²€ìƒ‰ í¬í•¨)
        base_results = self._execute_vector_search_readonly(search_query, search_filters, top_k * 2, debug)
        
        # ğŸ”— 6.5ë‹¨ê³„: DBì—ì„œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ Perplexity API ì‚¬ìš©
        if not base_results:
            print("ğŸ”— DBì—ì„œ ê²°ê³¼ê°€ ì—†ì–´ ì‹¤ì‹œê°„ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            if extracted_brands:
                return self._search_with_perplexity(query, extracted_brands[0])
            else:
                return self._search_with_perplexity(query)
        
        # 7ë‹¨ê³„: ê°œì¸í™” ìŠ¤ì½”ì–´ë§
        personalized_results = self._apply_personalization_scoring_readonly(
            base_results, user_profile, parsed_info, debug
        )
        
        # 8ë‹¨ê³„: ìµœì¢… ì •ë ¬ ë° ì„ íƒ
        final_results = self._rank_and_select_results(
            personalized_results, user_profile, top_k, debug
        )
        
        if debug:
            print(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(base_results)}ê°œ â†’ ê°œì¸í™” í›„: {len(final_results)}ê°œ")
        
        # 9ë‹¨ê³„: ê²°ê³¼ ì¶œë ¥
        if not final_results:
            # ğŸ”— ìµœì¢…ì ìœ¼ë¡œë„ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ Perplexity API ì‚¬ìš©
            print("ğŸ”— ìµœì¢… ê²°ê³¼ê°€ ì—†ì–´ ì‹¤ì‹œê°„ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            if extracted_brands:
                return self._search_with_perplexity(query, extracted_brands[0])
            else:
                return self._search_with_perplexity(query)
        
        return self._generate_results_readonly(final_results, user_profile, parsed_info)

    def _enhance_query_for_personalization(self, query: str, user_profile: Dict) -> str:
        """ğŸ¯ ê°œì¸í™” ìš”ì²­ì„ ìœ„í•œ ì¿¼ë¦¬ í™•ì¥"""
        # ì‚¬ìš©ì ìµœë‹¤ ì´ìš© ë¸Œëœë“œ 3ê°œ ì¶”ê°€
        top_brands = sorted(
            user_profile.get('brand_counts', {}).items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:3]
        
        # ì‚¬ìš©ì ìµœë‹¤ ì´ìš© ì¹´í…Œê³ ë¦¬ 2ê°œ ì¶”ê°€
        top_categories = user_profile.get('preferred_categories', [])[:2]
        
        enhanced_parts = [query]
        
        if top_brands:
            brand_names = [brand for brand, _ in top_brands]
            enhanced_parts.append(' '.join(brand_names))
        
        if top_categories:
            category_names = [category for category, _ in top_categories]
            enhanced_parts.append(' '.join(category_names))
        
        enhanced_parts.append('í˜œíƒ í• ì¸ ì´ë²¤íŠ¸ ì¶”ì²œ')
        
        return ' '.join(enhanced_parts)

    def _validate_query_improved(self, query: str, analysis: Dict, parsed_info: Dict, 
                               extracted_brands: List[str], is_personalization: bool, debug: bool) -> Dict[str, Any]:
        """ğŸ”§ ê°œì„ ëœ ì¿¼ë¦¬ ê²€ì¦ (ë¸Œëœë“œ ì¸ì‹ ë° ê°œì¸í™” ìš”ì²­ ì²˜ë¦¬ ê°œì„ )"""
        
        if debug:
            print("ğŸ”§ ê°œì„ ëœ ì¿¼ë¦¬ ê²€ì¦ ì‹œì‘...")
            print(f"   ğŸ¯ ê°œì¸í™” ìš”ì²­: {is_personalization}")
            print(f"   ğŸª ì¶”ì¶œëœ ë¸Œëœë“œ: {extracted_brands}")
        
        # ğŸ¯ 1) ê°œì¸í™” ìš”ì²­ì´ë©´ ë¬´ì¡°ê±´ í†µê³¼
        if is_personalization:
            if debug:
                print("   âœ… ê°œì¸í™” ìš”ì²­ìœ¼ë¡œ ì¸ì‹ - ê²€ìƒ‰ ì§„í–‰")
            return {'valid': True}
        
        # 2) ëª…ì‹œì  ì†Œë¹„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¸Œëœë“œ ì¡´ì¬ í™•ì¸
        if parsed_info.get('spending_data'):
            brands = list(parsed_info['spending_data'].keys())
            brand_existence = self._check_brand_existence(brands, debug)
            
            missing_brands = [brand for brand, exists in brand_existence.items() if not exists]
            if missing_brands:
                if debug:
                    print(f"   âŒ ì†Œë¹„ ë°ì´í„°ì˜ ë¸Œëœë“œ '{', '.join(missing_brands)}'ê°€ DBì— ì—†ìŒ")
                return {
                    'valid': False,
                    'message': self._generate_missing_brands_message(missing_brands, 'spending_data')
                }
            
            if debug:
                print("   âœ… ì†Œë¹„ ë°ì´í„°ì˜ ëª¨ë“  ë¸Œëœë“œê°€ DBì— ì¡´ì¬ - ê²€ìƒ‰ ì§„í–‰")
            return {'valid': True}
        
        # ğŸ”§ 3) ì¶”ì¶œëœ ë¸Œëœë“œê°€ ìˆì„ ë•Œë§Œ ì¡´ì¬ í™•ì¸
        if extracted_brands:
            brand_existence = self._check_brand_existence(extracted_brands, debug)
            missing_brands = [brand for brand, exists in brand_existence.items() if not exists]
            
            # ğŸ”§ ëª¨ë“  ë¸Œëœë“œê°€ ì—†ì„ ë•Œë§Œ ì°¨ë‹¨ (Perplexityë¡œ ë„˜ê¹€)
            if missing_brands and len(missing_brands) == len(extracted_brands):
                if debug:
                    print(f"   âŒ ì¶”ì¶œëœ ëª¨ë“  ë¸Œëœë“œ '{', '.join(missing_brands)}'ê°€ DBì— ì—†ìŒ - Perplexityë¡œ ì „í™˜")
                return {
                    'valid': False,
                    'message': f"ë¸Œëœë“œ '{', '.join(missing_brands)}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤."
                }
            elif missing_brands:
                if debug:
                    existing_brands = [b for b in extracted_brands if b not in missing_brands]
                    print(f"   âš ï¸ ì¼ë¶€ ë¸Œëœë“œë§Œ ì¡´ì¬: ì¡´ì¬={existing_brands}, ì—†ìŒ={missing_brands}")
                    print("   âœ… ì¡´ì¬í•˜ëŠ” ë¸Œëœë“œ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰ ì§„í–‰")
            else:
                if debug:
                    print("   âœ… ì¶”ì¶œëœ ëª¨ë“  ë¸Œëœë“œê°€ DBì— ì¡´ì¬ - ê²€ìƒ‰ ì§„í–‰")
            return {'valid': True}
        
        # 4) í˜œíƒ í‚¤ì›Œë“œë‚˜ ì¼ë°˜ì ì¸ ì¶”ì²œ ìš”ì²­ì´ë©´ í•­ìƒ í†µê³¼
        benefit_keywords = ['í˜œíƒ', 'í• ì¸', 'ì´ë²¤íŠ¸', 'ì ë¦½', 'ì¿ í°', 'ì¦ì •', 'íŠ¹ê°€', 'ì„¸ì¼', 'ì¶”ì²œ']
        general_keywords = ['ë§ëŠ”', 'íŒ¨í„´', 'ì†Œë¹„', 'ë‚´', 'ìš°ë¦¬', 'ì¢‹ì€', 'ê´œì°®ì€', 'ì–´ë–¤', 'ë­ê°€']
        
        has_benefit_keyword = any(keyword in query for keyword in benefit_keywords)
        has_general_keyword = any(keyword in query for keyword in general_keywords)
        
        if has_benefit_keyword or has_general_keyword:
            if debug:
                if has_benefit_keyword:
                    print("   âœ… í˜œíƒ í‚¤ì›Œë“œ ì¸ì‹ë¨ - ì¼ë°˜ ê²€ìƒ‰ ì§„í–‰")
                if has_general_keyword:
                    print("   âœ… ì¼ë°˜ ì¶”ì²œ ìš”ì²­ ì¸ì‹ë¨ - ê²€ìƒ‰ ì§„í–‰")
            return {'valid': True}
        
        # 5) ë¹ˆ ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬ë„ í†µê³¼ (ì‚¬ìš©ìê°€ ëª¨ë¥´ê³  ë¬¼ì–´ë³¼ ìˆ˜ ìˆìŒ)
        if debug:
            print("   âœ… ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬ ì—†ëŠ” ì¼ë°˜ ì§ˆë¬¸ - ì „ì²´ ê²€ìƒ‰ ì§„í–‰")
        return {'valid': True}

    def _execute_vector_search_readonly(self, query: str, filters: Dict, top_k: int, debug: bool = False) -> List[Dict]:
        """ğŸ”’ ê°œì„ ëœ ë²¡í„° ê²€ìƒ‰ (ë¸Œëœë“œ > ì¹´í…Œê³ ë¦¬ ìš°ì„ ìˆœìœ„)"""
        try:
            # ğŸ”§ ë¸Œëœë“œì™€ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì¶”ì¶œ
            extracted_brands = self._extract_brands_from_query(query, debug)
            extracted_categories = self._extract_categories_from_query(query, debug)
            
            if debug:
                print(f"ğŸ” ì¶”ì¶œ ê²°ê³¼ - ë¸Œëœë“œ: {extracted_brands}, ì¹´í…Œê³ ë¦¬: {extracted_categories}")
            
            # ğŸ”§ 1ë‹¨ê³„: ë¸Œëœë“œê°€ ìˆìœ¼ë©´ ë¸Œëœë“œ ìš°ì„  (ì¹´í…Œê³ ë¦¬ ë¬´ì‹œ)
            if extracted_brands:
                brand_results = self._try_direct_brand_search(query, top_k, debug)
                if brand_results:
                    print(f"âœ… ë¸Œëœë“œ ìš°ì„  ê²€ìƒ‰ ì„±ê³µ: {len(brand_results)}ê°œ ê²°ê³¼ (ë¸Œëœë“œ: {extracted_brands})")
                    return brand_results
                else:
                    if debug:
                        print(f"âš ï¸ ë¸Œëœë“œ '{extracted_brands}' ì§ì ‘ ê²€ìƒ‰ ì‹¤íŒ¨, ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì§„í–‰...")
            
            # ğŸ”§ 2ë‹¨ê³„: ë¸Œëœë“œê°€ ì—†ê³  ì¹´í…Œê³ ë¦¬ë§Œ ìˆìœ¼ë©´ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰
            elif extracted_categories:
                category_results = self._try_direct_category_search(query, extracted_categories, top_k, debug)
                if category_results:
                    print(f"âœ… ì¹´í…Œê³ ë¦¬ ìš°ì„  ê²€ìƒ‰ ì„±ê³µ: {len(category_results)}ê°œ ê²°ê³¼ (ì¹´í…Œê³ ë¦¬: {extracted_categories})")
                    return category_results
                else:
                    if debug:
                        print(f"âš ï¸ ì¹´í…Œê³ ë¦¬ '{extracted_categories}' ì§ì ‘ ê²€ìƒ‰ ì‹¤íŒ¨, ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì§„í–‰...")
            
            # ğŸ”§ 3ë‹¨ê³„: ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬ ì§ì ‘ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ë²¡í„° ê²€ìƒ‰
            search_query = query
            
            if debug:
                print(f"ğŸ” ë²¡í„° ê²€ìƒ‰ ì‹œì‘: '{search_query}'")
            
            # ì„ë² ë”© ìƒì„±
            try:
                request_data = {"text": search_query}
                query_vector = self.embedding_executor.execute(request_data)
                
                if not query_vector:
                    print("âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ - í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
                    return self._fallback_text_search(query, filters, top_k, debug)
                    
            except Exception as e:
                print(f"âŒ ì„ë² ë”© API ì˜¤ë¥˜: {e} - í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
                return self._fallback_text_search(query, filters, top_k, debug)
            
            # ë²¡í„° ì •ê·œí™”
            try:
                query_vector_array = np.array(query_vector)
                norm = np.linalg.norm(query_vector_array)
                
                if norm > 0:
                    normalized_query_vector = (query_vector_array / norm).tolist()
                else:
                    normalized_query_vector = query_vector
                    
            except Exception as e:
                print(f"âš ï¸ ë²¡í„° ì •ê·œí™” ì˜¤ë¥˜: {e}")
                normalized_query_vector = query_vector
            
            # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰
            try:
                results = self.collection.query(
                    query_embeddings=[normalized_query_vector],
                    n_results=top_k * 3,
                    include=["metadatas", "distances", "documents"]
                )
                
                if debug:
                    result_count = len(results['ids'][0]) if results and results.get('ids') else 0
                    print(f"ğŸ” ì¼ë°˜ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼: {result_count}ê°œ")
                    
            except Exception as e:
                print(f"âŒ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e} - í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
                return self._fallback_text_search(query, filters, top_k, debug)
            
            # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê²€ìƒ‰
            if not results or not results.get('ids') or not results['ids'][0]:
                print("âŒ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
                return self._fallback_text_search(query, filters, top_k, debug)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_results = []
            ids = results['ids'][0]
            metadatas = results['metadatas'][0] 
            distances = results['distances'][0]
            documents = results['documents'][0]
            
            for i in range(len(ids)):
                formatted_results.append({
                    "id": ids[i],
                    "metadata": metadatas[i],
                    "distance": distances[i],
                    "document": documents[i],
                    "vector_rank": i + 1
                })
            
            print(f"âœ… ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(formatted_results)}ê°œ ê²°ê³¼")
            return formatted_results
            
        except Exception as e:
            print(f"âŒ ë²¡í„° ê²€ìƒ‰ ì „ì²´ ì‹¤íŒ¨: {e} - í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
            return self._fallback_text_search(query, filters, top_k, debug)

    def _apply_personalization_scoring_readonly(self, results: List[Dict], user_profile: Dict, 
                                              parsed_info: Dict, debug: bool) -> List[Dict]:
        """ğŸ”’ ê°œì¸í™” ìŠ¤ì½”ì–´ë§ (ì½ê¸° ì „ìš©)"""
        if not results:
            print("âŒ ê°œì¸í™” ìŠ¤ì½”ì–´ë§: ì…ë ¥ ê²°ê³¼ ì—†ìŒ")
            return []
        
        print(f"ğŸ”„ ê°œì¸í™” ìŠ¤ì½”ì–´ë§: {len(results)}ê°œ ê²°ê³¼")
        
        scored_results = []
        current_date = datetime.now()
        
        # ì „ì²´ ê±°ë¦¬ê°’ ìˆ˜ì§‘ (ìƒëŒ€ì  ê³„ì‚°ìš©)
        all_distances = [result.get('distance', 0) for result in results]
        
        for i, result in enumerate(results):
            try:
                metadata = result.get('metadata', {})
                brand = metadata.get('brand')
                category = metadata.get('category')
                benefit_type = metadata.get('benefit_type')
                discount_rate = float(metadata.get('discount_rate', 0))
                
                # ê¸°ë³¸ ê²€ì¦
                if not self._validate_result(metadata, current_date):
                    continue
                
                # ê°œì¸í™” ì ìˆ˜ ê³„ì‚°
                vector_score = self.calculate_vector_similarity_universal(result.get('distance', 0), all_distances)
                
                # ìµœì¢… ê°œì¸í™” ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í™”)
                personalized_score = vector_score * 0.8 + 0.2  # ë²¡í„° ìœ ì‚¬ë„ 80% + ê¸°ë³¸ ì ìˆ˜ 20%
                
                # ê²°ê³¼ì— ì ìˆ˜ ì €ì¥
                result['personalized_score'] = personalized_score
                result['vector_score'] = vector_score
                
                scored_results.append(result)
                
            except Exception as e:
                if debug:
                    print(f"      âŒ ì˜¤ë¥˜: {e}")
                continue
        
        print(f"âœ… ê°œì¸í™” ìŠ¤ì½”ì–´ë§ ì™„ë£Œ: {len(scored_results)}/{len(results)}ê°œ ì²˜ë¦¬")
        return scored_results
    
    def _validate_result(self, metadata: Dict, current_date: datetime) -> bool:
        """ê²°ê³¼ ìœ íš¨ì„± ê²€ì¦"""
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if not all([metadata.get('brand'), metadata.get('category'), 
                   metadata.get('title'), metadata.get('benefit_type')]):
            return False
        
        # í™œì„± ìƒíƒœ ê²€ì¦
        if not metadata.get('is_active', False):
            return False
        
        # ë‚ ì§œ ìœ íš¨ì„± ê²€ì¦
        if metadata.get('valid_to'):
            try:
                valid_to = datetime.fromisoformat(metadata['valid_to'])
                if valid_to < current_date:
                    return False
            except:
                return False
        
        return True
    
    def _rank_and_select_results(self, results: List[Dict], user_profile: Dict, 
                               top_k: int, debug: bool) -> List[Dict]:
        """ìµœì¢… ìˆœìœ„ ê²°ì • ë° ê²°ê³¼ ì„ íƒ"""
        if not results:
            return []
        
        # ê°œì¸í™” ì ìˆ˜ë¡œ ì •ë ¬
        try:
            sorted_results = sorted(results, key=lambda x: x.get('personalized_score', 0), reverse=True)
        except Exception as e:
            return results[:top_k]
        
        return sorted_results[:top_k]
    
    def _generate_results_readonly(self, results: List[Dict], user_profile: Dict, parsed_info: Dict = None) -> str:
        """ğŸ”’ ê²€ìƒ‰ ê²°ê³¼ ìƒì„± (ì½ê¸° ì „ìš©)"""
        if not results:
            return "âŒ í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” í˜œíƒ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            message = f"ğŸ¯ ê°œì¸í™” í˜œíƒ ì¶”ì²œ ê²°ê³¼:\n\n"
            
            for i, result in enumerate(results[:5], 1):
                metadata = result.get('metadata', {})
                score = result.get('personalized_score', 0)
                
                message += f"**[{i}] {metadata.get('brand', 'Unknown')}** ({metadata.get('category', 'Unknown')})\n"
                message += f"ğŸ¯ {metadata.get('title', 'Unknown')}\n"
                
                # í˜œíƒ ì •ë³´
                benefit_type = metadata.get('benefit_type', 'Unknown')
                discount_rate = metadata.get('discount_rate', 0)
                
                try:
                    discount_rate = float(discount_rate) if discount_rate else 0
                except:
                    discount_rate = 0
                
                if benefit_type == "í• ì¸" and discount_rate > 0:
                    message += f"ğŸ’° {benefit_type}: {discount_rate}% í• ì¸\n"
                elif benefit_type == "ì ë¦½" and discount_rate > 0:
                    message += f"ğŸ’° {benefit_type}: {discount_rate}ë°° ì ë¦½\n"
                else:
                    message += f"ğŸ’° í˜œíƒ: {benefit_type}\n"
                
                conditions = metadata.get('conditions', 'ì¡°ê±´ ì—†ìŒ')
                message += f"ğŸ“ ì¡°ê±´: {conditions}\n"
                
                valid_from = metadata.get('valid_from', 'Unknown')
                valid_to = metadata.get('valid_to', 'Unknown') 
                message += f"ğŸ“… ê¸°ê°„: {valid_from} ~ {valid_to}\n"
                message += f"ğŸ“Š ê°œì¸í™”ì ìˆ˜: {score:.3f}\n\n"
            
            return message.strip()
            
        except Exception as e:
            return f"ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œì˜ í˜œíƒì„ ì°¾ì•˜ì§€ë§Œ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _generate_no_results_message_enhanced(self, parsed_info: Dict, user_profile: Dict, analysis: Dict) -> str:
        """ğŸ” í–¥ìƒëœ ê²°ê³¼ ì—†ìŒ ë©”ì‹œì§€"""
        return "âŒ í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” í˜œíƒ ì •ë³´ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ìŠµë‹ˆë‹¤."

    def _generate_missing_brands_message(self, missing_brands: List[str], context: str) -> str:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¸Œëœë“œì— ëŒ€í•œ ë©”ì‹œì§€ ìƒì„±"""
        if len(missing_brands) == 1:
            brand = missing_brands[0]
            message = f"âŒ '{brand}' ë¸Œëœë“œëŠ” í˜„ì¬ í˜œíƒ ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
        else:
            brand_list = "', '".join(missing_brands)
            message = f"âŒ '{brand_list}' ë¸Œëœë“œë“¤ì€ í˜„ì¬ í˜œíƒ ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
        
        return message


# API í´ë˜ìŠ¤ë“¤
class CompletionExecutor:
    def __init__(self, host, api_key, request_id):
        self._host = host
        self._api_key = api_key
        self._request_id = request_id

    def execute(self, completion_request):
        headers = {
            'Authorization': self._api_key,
            'X-NCP-CLOVASTUDIO-REQUEST-ID': self._request_id,
            'Content-Type': 'application/json; charset=utf-8',
            'Accept': 'text/event-stream'
        }

        final_answer = ""
        
        with requests.post(
            self._host + '/v3/chat-completions/HCX-005',
            headers=headers,
            json=completion_request,
            stream=True
        ) as r:
            for line in r.iter_lines():
                if line:
                    decoded_line = line.decode("utf-8")
                    
                    if decoded_line.startswith("data:"):
                        if decoded_line.endswith("[DONE]"):
                            break
                            
                        try:
                            json_str = decoded_line[5:]
                            event_data = json.loads(json_str)
                            
                            if (event_data.get('finishReason') == 'stop' and 
                                'message' in event_data and 
                                'content' in event_data['message']):
                                final_answer = event_data['message']['content']
                                break
                                
                        except json.JSONDecodeError:
                            continue
        
        return final_answer


class EmbeddingExecutor:
    def __init__(self, host, api_key, request_id):
        self._host = host
        self._api_key = api_key
        self._request_id = request_id

    def execute(self, request_data):
        headers = {
            'Content-Type': 'application/json; charset=utf-8',
            'Authorization': self._api_key,
            'X-NCP-CLOVASTUDIO-REQUEST-ID': self._request_id
        }

        response = requests.post(
            f"https://{self._host}/v1/api-tools/embedding/clir-emb-dolphin",
            headers=headers,
            json=request_data
        )
        
        if response.status_code == 200:
            result = response.json()
            if result['status']['code'] == '20000':
                return result['result']['embedding']
        
        raise Exception(f"ì„ë² ë”© API ì˜¤ë¥˜: {response.status_code}")


# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¯ ê°œì„ ëœ ê°œì¸í™” í˜œíƒ ì¶”ì²œ RAG ì‹œìŠ¤í…œ + Perplexity API ì—°ë™")
    print("=" * 80)
    print("ğŸ”§ ì£¼ìš” ê¸°ëŠ¥:")
    print("   âœ… ê¸°ì¡´ RAG ì‹œìŠ¤í…œ (DB ê¸°ë°˜ ê²€ìƒ‰)")
    print("   ğŸ”— Perplexity API ì—°ë™ (ì‹¤ì‹œê°„ ê²€ìƒ‰)")
    print("   ğŸ¯ ìë™ ì „í™˜: DBì— ì—†ëŠ” ë¸Œëœë“œ â†’ ì‹¤ì‹œê°„ ê²€ìƒ‰")
    print("   ğŸ“Š ê°œì¸í™” ì¶”ì²œ ì‹œìŠ¤í…œ")
    print("ğŸš€ ì´ì œ ëª¨ë“  ë¸Œëœë“œ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰ ê°€ëŠ¥!")
    print("=" * 80)
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag = PersonalizedBenefitRAG()
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    if not rag.connect_database():
        print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    sample_history = create_sample_user_history()
    user_profile = rag.create_user_profile(sample_history)
    
    # ì‚¬ìš©ì í”„ë¡œí•„ ìš”ì•½ ì¶œë ¥
    print(f"   ğŸ“Š ì´ ì†Œë¹„: {user_profile['total_spending']:,.0f}ì› ({user_profile['total_transactions']}ê±´)")
    print(f"   â­ ì„ í˜¸ ë¸Œëœë“œ: {dict(list(sorted(user_profile['brand_counts'].items(), key=lambda x: x[1], reverse=True))[:3])}")
    print(f"   ğŸ·ï¸ ì„ í˜¸ ì¹´í…Œê³ ë¦¬: {dict(user_profile['preferred_categories'][:3])}")
    print(f"   ğŸ“… ìµœê·¼ 1ì£¼ì¼ ì†Œë¹„: {len(user_profile.get('recent_brands', []))}ê±´")
    
    debug_mode = False
    

    try:
        query = input("\nğŸ”§ ì§ˆë¬¸: ").strip()
        
        print("\nâ³ ì—°ê²°ëœ RAG + Perplexity ê²€ìƒ‰ ì¤‘...")
        
        # ğŸ”— ê°œì¸í™” í˜œíƒ ê²€ìƒ‰ ë° ì¶”ì²œ (Perplexity ì—°ë™)
        answer = rag.search_personalized_benefits(query, user_profile, debug=debug_mode)
        
        print(f"\nğŸ”— ì¶”ì²œ ê²°ê³¼:\n{answer}")
        print("-" * 80)
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        


if __name__ == "__main__":
    main()
