import json
import logging
import datetime
import requests
from flask import jsonify, request
import re
from typing import Dict, Any, List, Optional

class EC2ScoreCalculator:
    """EC2 ì„œë²„ìš© ê°œì¸í™” ì ìˆ˜ ê³„ì‚°ê¸°"""
    
    @staticmethod
    def calculate_preference_score(brand: str, category: str, user_history: Dict) -> float:
        """ê°œì¸ ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° (0-1)"""
        try:
            brand_count = user_history.get('brand_counts', {}).get(brand, 0)
            category_count = user_history.get('category_counts', {}).get(category, 0) 
            total_transactions = user_history.get('total_transactions', 1)
            
            if total_transactions == 0:
                return 0.0
            
            # ë¸Œëœë“œ ì„ í˜¸ë„ (ê°€ì¤‘ì¹˜ 70%)
            brand_preference = brand_count / total_transactions
            
            # ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„ (ê°€ì¤‘ì¹˜ 30%)
            category_preference = category_count / total_transactions
            
            return (brand_preference * 0.7) + (category_preference * 0.3)
            
        except Exception as e:
            logger.error(f"ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.0
    
    @staticmethod
    def calculate_potential_savings(benefit_type: str, discount_rate: float, 
                                  user_avg_spending: float) -> float:
        """ì˜ˆìƒ ì ˆê°ì•¡ ê³„ì‚° (ì› ë‹¨ìœ„)"""
        try:
            discount_rate = float(discount_rate) if discount_rate != 'N/A' else 0
            user_avg_spending = float(user_avg_spending) if user_avg_spending else 0
            
            if benefit_type == "í• ì¸":
                return user_avg_spending * (discount_rate / 100)
            elif benefit_type == "ì ë¦½":
                return user_avg_spending * (discount_rate / 100) * 0.5
            elif benefit_type == "ì¦ì •":
                return user_avg_spending * 0.2
            else:
                return user_avg_spending * 0.1
                
        except Exception as e:
            logger.error(f"ì ˆê°ì•¡ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.0
    
    @staticmethod
    def calculate_recency_weight(spending_date: str, current_date: datetime = None) -> float:
        """ìµœê·¼ì„± ê°€ì¤‘ì¹˜ ê³„ì‚° (0-1)"""
        try:
            if current_date is None:
                current_date = datetime.now()
            
            # ë¬¸ìì—´ ë‚ ì§œë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
            if isinstance(spending_date, str):
                try:
                    spending_dt = datetime.fromisoformat(spending_date.replace('Z', '+00:00'))
                except:
                    spending_dt = datetime.strptime(spending_date, '%Y-%m-%d')
            else:
                spending_dt = spending_date
            
            days_diff = (current_date - spending_dt).days
            
            if days_diff <= 7:
                return 1.0
            elif days_diff <= 30:
                return 0.8
            elif days_diff <= 90:
                return 0.5
            else:
                return 0.2
                
        except Exception as e:
            
            return 0.2


class EC2PersonalizedRAG:
    """EC2 ì„œë²„ì— ìµœì í™”ëœ ê°œì¸í™” RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.db_path = config['db_path']
        self.collection_name = config['collection_name']
        self.client = None
        self.collection = None
        self.score_calculator = EC2ScoreCalculator()
        
        # ìºì‹œëœ ë©”íƒ€ë°ì´í„°
        self.available_brands: Set[str] = set()
        self.available_categories: Set[str] = set()
        self.db_metadata_loaded = False
        
        logger.info("ğŸš€ EC2PersonalizedRAG ì´ˆê¸°í™” ì™„ë£Œ")
    
    def connect_database(self) -> bool:
        """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ í™•ì¸ ë° ìƒì„±
            if not os.path.exists(self.db_path):
                logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.db_path}")
                # ë””ë ‰í† ë¦¬ ìƒì„± ì‹œë„
                try:
                    os.makedirs(self.db_path, exist_ok=True)
                    logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ ìƒì„±: {self.db_path}")
                except Exception as e:
                    logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
                    return False
            
            # ChromaDB ì—°ê²°
            self.client = chromadb.PersistentClient(path=self.db_path)
            
            try:
                # ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ ì‹œë„
                self.collection = self.client.get_collection(name=self.collection_name)
                logger.info(f"âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ ì„±ê³µ: {self.collection_name}")
            except Exception:
                # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ìƒì„±
                logger.warning(f"ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {self.collection_name}")
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    metadata={"hnsw:space": "ip"}
                )
                logger.info(f"âœ… ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ: {self.collection_name}")
            
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            self._load_database_metadata()
            
            logger.info(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ: {self.db_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def _load_database_metadata(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        try:
            if not self.collection:
                return
            
            # ì»¬ë ‰ì…˜ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
            count = self.collection.count()
            if count == 0:
                logger.warning("ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
                return
            
            # ìƒ˜í”Œ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            sample_results = self.collection.get(
                limit=min(1000, count),  # ìµœëŒ€ 1000ê°œ ë˜ëŠ” ì „ì²´ ê°œìˆ˜
                include=['metadatas']
            )
            
            if sample_results and sample_results.get('metadatas'):
                for metadata in sample_results['metadatas']:
                    if metadata.get('brand'):
                        self.available_brands.add(metadata['brand'])
                    if metadata.get('category'):
                        self.available_categories.add(metadata['category'])
            
            self.db_metadata_loaded = True
            logger.info(f"ğŸ“Š ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ë¸Œëœë“œ {len(self.available_brands)}ê°œ, ì¹´í…Œê³ ë¦¬ {len(self.available_categories)}ê°œ, ì´ ë¬¸ì„œ {count}ê°œ")
            
        except Exception as e:
            logger.error(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
    
    def generate_embedding(self, text: str) -> Optional[List[float]]:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        try:
            headers = EC2Config.get_api_headers(self.config, 'embedding')
            url = EC2Config.API_ENDPOINTS['embedding']
            
            # ìš”ì²­ ë°ì´í„° ì¤€ë¹„
            payload = {"text": text}
            
            # API í˜¸ì¶œ
            response = requests.post(
                url,
                headers=headers,
                json=payload,
                timeout=self.config['embedding_timeout']
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('status', {}).get('code') == '20000':
                    embedding = result.get('result', {}).get('embedding')
                    if embedding:
                        logger.debug(f"ì„ë² ë”© ìƒì„± ì„±ê³µ: í…ìŠ¤íŠ¸ ê¸¸ì´ {len(text)}, ë²¡í„° ì°¨ì› {len(embedding)}")
                        return embedding
            
            logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: HTTP {response.status_code}")
            return None
            
        except requests.exceptions.Timeout:
            logger.error(f"ì„ë² ë”© API íƒ€ì„ì•„ì›ƒ ({self.config['embedding_timeout']}ì´ˆ)")
            return None
        except Exception as e:
            logger.error(f"ì„ë² ë”© API ì˜¤ë¥˜: {e}")
            return None
    
    def search_benefits(self, query: str, user_history: Optional[Dict] = None, 
                       top_k: int = None, debug: bool = False) -> Dict[str, Any]:
        """í˜œíƒ ê²€ìƒ‰ ë° ê°œì¸í™” ì¶”ì²œ"""
        try:
            if top_k is None:
                top_k = self.config['top_k']
            
            logger.info(f"ğŸ” í˜œíƒ ê²€ìƒ‰ ì‹œì‘: '{query}' (top_k={top_k})")
            
            # 1. ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ì‹œë„
            categories = self._extract_categories_from_query(query, debug)
            
            # 2. ë¸Œëœë“œ ì¶”ì¶œ ì‹œë„
            brands = self._extract_brands_from_query(query, debug)
            
            # 3. ê²€ìƒ‰ ì „ëµ ê²°ì • ë° ì‹¤í–‰
            results = []
            
            # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì§ì ‘ ê²€ìƒ‰
            if categories:
                direct_results = self._direct_category_search(categories, top_k, debug)
                results.extend(direct_results)
            
            # ë¸Œëœë“œ ê¸°ë°˜ ì§ì ‘ ê²€ìƒ‰
            if brands:
                brand_results = self._direct_brand_search(brands, top_k, debug)
                results.extend(brand_results)
            
            # ë²¡í„° ê²€ìƒ‰ (ì„ë² ë”© ê¸°ë°˜)
            if len(results) < top_k:
                vector_results = self._vector_search(query, top_k - len(results), debug)
                results.extend(vector_results)
            
            # 4. ê°œì¸í™” ì ìˆ˜ ì ìš©
            if user_history:
                results = self._apply_personalization(results, user_history, debug)
            
            # 5. ê²°ê³¼ ì •ë¦¬ ë° ë°˜í™˜
            final_results = self._finalize_results(results, top_k)
            
            # 6. ì›¹ ê²€ìƒ‰ ë³´ì™„ (ê²°ê³¼ê°€ 3ê°œ ë¯¸ë§Œì¸ ê²½ìš°)
            if len(final_results) < 3:
                logger.info(f"ğŸŒ ê²€ìƒ‰ ê²°ê³¼ ë¶€ì¡± ({len(final_results)}ê°œ) - ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë³´ì™„")
                web_results = self._supplement_with_web_search(query, categories, brands, 5 - len(final_results))
                final_results.extend(web_results)
                logger.info(f"ğŸ”„ ì›¹ ê²€ìƒ‰ ë³´ì™„ í›„: {len(final_results)}ê°œ ê²°ê³¼")
            
            logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)}ê°œ ê²°ê³¼ ë°˜í™˜")
            
            return {
                "success": True,
                "query": query,
                "extracted_categories": categories,
                "extracted_brands": brands,
                "results": final_results,
                "total_found": len(final_results),
                "search_strategy": self._get_search_strategy_info(categories, brands),
                "web_search_used": len(final_results) > len(self._finalize_results(results, top_k)),
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return self._generate_error_response(str(e), query)
    
    def _extract_categories_from_query(self, query: str, debug: bool = False) -> List[str]:
        """ì¿¼ë¦¬ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
        found_categories = []
        query_lower = query.lower()
        
        for category, keywords in EC2Config.CATEGORIES.items():
            for keyword in keywords:
                if keyword.lower() in query_lower:
                    found_categories.append(category)
                    if debug:
                        logger.debug(f"ì¹´í…Œê³ ë¦¬ ë°œê²¬: {category} (í‚¤ì›Œë“œ: {keyword})")
                    break
        
        return list(set(found_categories))
    
    def _extract_brands_from_query(self, query: str, debug: bool = False) -> List[str]:
        """ì¿¼ë¦¬ì—ì„œ ë¸Œëœë“œ ì¶”ì¶œ"""
        found_brands = []
        query_lower = query.lower()
        
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¡œë“œëœ ë¸Œëœë“œë“¤ í™•ì¸
        for brand in self.available_brands:
            if brand.lower() in query_lower:
                found_brands.append(brand)
                if debug:
                    logger.debug(f"ë¸Œëœë“œ ë°œê²¬: {brand}")
        
        return list(set(found_brands))
    
    def _direct_category_search(self, categories: List[str], top_k: int, debug: bool = False) -> List[Dict]:
        """ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì§ì ‘ ê²€ìƒ‰"""
        results = []
        
        try:
            for category in categories:
                category_results = self.collection.get(
                    where={"category": {"$eq": category}},
                    limit=top_k,
                    include=["metadatas", "documents"]
                )
                
                if category_results and category_results.get('metadatas'):
                    for i, metadata in enumerate(category_results['metadatas']):
                        if self._validate_result(metadata):
                            results.append({
                                "id": f"cat_{category}_{i}",
                                "metadata": metadata,
                                "document": category_results['documents'][i] if category_results.get('documents') else "",
                                "distance": 0.0,  # ì§ì ‘ ë§¤ì¹­
                                "similarity_score": 1.0,
                                "search_type": "category_direct"
                            })
                
                if debug:
                    count = len(category_results['metadatas']) if category_results and category_results.get('metadatas') else 0
                    logger.debug(f"ì¹´í…Œê³ ë¦¬ '{category}': {count}ê°œ ê²°ê³¼")
        
        except Exception as e:
            logger.error(f"ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        return results
    
    def _direct_brand_search(self, brands: List[str], top_k: int, debug: bool = False) -> List[Dict]:
        """ë¸Œëœë“œ ê¸°ë°˜ ì§ì ‘ ê²€ìƒ‰"""
        results = []
        
        try:
            for brand in brands:
                brand_results = self.collection.get(
                    where={"brand": {"$eq": brand}},
                    limit=top_k,
                    include=["metadatas", "documents"]
                )
                
                if brand_results and brand_results.get('metadatas'):
                    for i, metadata in enumerate(brand_results['metadatas']):
                        if self._validate_result(metadata):
                            results.append({
                                "id": f"brand_{brand}_{i}",
                                "metadata": metadata,
                                "document": brand_results['documents'][i] if brand_results.get('documents') else "",
                                "distance": 0.0,
                                "similarity_score": 1.0,
                                "search_type": "brand_direct"
                            })
                
                if debug:
                    count = len(brand_results['metadatas']) if brand_results and brand_results.get('metadatas') else 0
                    
        
        except Exception as e:
            return
        
        return results  
    
    def _vector_search(self, query: str, top_k: int, debug: bool = False) -> List[Dict]:
        """ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰"""
        try:
            embedding = self.generate_embedding(query)
            if not embedding:
                if debug:
                    logger.debug("ì„ë² ë”© ìƒì„± ì‹¤íŒ¨, ë²¡í„° ê²€ìƒ‰ ìƒëµ")
                return []
            
            results = self.collection.query(
                query_embeddings=[embedding],
                n_results=top_k,
                include=['documents', 'metadatas', 'distances']
            )
            
            vector_results = []
            if results.get('documents') and results['documents'][0]:
                documents = results['documents'][0]
                metadatas = results.get('metadatas', [[]])[0]
                distances = results.get('distances', [[]])[0]
                
                for i, (doc, metadata, distance) in enumerate(zip(documents, metadatas, distances)):
                    if self._validate_result(metadata):
                        similarity = self._calculate_similarity_score(distance)
                        vector_results.append({
                            "id": f"vector_{i}",
                            "metadata": metadata,
                            "document": doc,
                            "distance": distance,
                            "similarity_score": similarity,
                            "search_type": "vector"
                        })
            
            
            
            return vector_results
            
        except Exception as e:
            
            return []
    
    def _calculate_similarity_score(self, distance: float) -> float:
        """ê±°ë¦¬ê°’ì„ ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ë³€í™˜"""
        try:
            # ê±°ë¦¬ê°’ì´ ìŒìˆ˜ì¸ ê²½ìš° (Inner Product)
            if distance < 0:
                # -1000 ~ 0 ë²”ìœ„ë¥¼ 0 ~ 1ë¡œ ì •ê·œí™”
                return max(0, min(1, (distance + 1000) / 1000))
            else:
                # ì¼ë°˜ì ì¸ ê±°ë¦¬ê°’ (L2, Cosine)
                return max(0, min(1, 1 - distance))
        except:
            return 0.5
    
    def _apply_personalization(self, results: List[Dict], user_history: Dict, debug: bool = False) -> List[Dict]:
        """ê°œì¸í™” ì ìˆ˜ ì ìš©"""
        try:
            for result in results:
                metadata = result.get('metadata', {})
                
                # ê¸°ë³¸ ì ìˆ˜ë“¤ ê³„ì‚°
                preference_score = self.score_calculator.calculate_preference_score(
                    metadata.get('brand', ''),
                    metadata.get('category', ''),
                    user_history
                )
                
                # ì˜ˆìƒ ì ˆê°ì•¡ ê³„ì‚°
                user_avg_spending = user_history.get('average_spending', {}).get(
                    metadata.get('category', ''), 50000
                )
                potential_savings = self.score_calculator.calculate_potential_savings(
                    metadata.get('benefit_type', ''),
                    metadata.get('discount_rate', 0),
                    user_avg_spending
                )
                
                # ìµœì¢… ê°œì¸í™” ì ìˆ˜ ê³„ì‚°
                base_score = result.get('similarity_score', 0.5)
                personalization_weight = self.config['personalization_weight']
                
                final_score = (base_score * (1 - personalization_weight)) + (preference_score * personalization_weight)
                
                # ê²°ê³¼ì— ì ìˆ˜ë“¤ ì¶”ê°€
                result.update({
                    'preference_score': preference_score,
                    'potential_savings': potential_savings,
                    'personalized_score': final_score,
                    'base_similarity': base_score
                })
                
                if debug:
                    logger.debug(f"ê°œì¸í™” ì ìˆ˜ - {metadata.get('brand', 'N/A')}: {final_score:.3f}")
            
            # ê°œì¸í™” ì ìˆ˜ë¡œ ì •ë ¬
            results.sort(key=lambda x: x.get('personalized_score', 0), reverse=True)
            
        except Exception as e:
            
        
            return results
    
    def _validate_result(self, metadata: Dict) -> bool:
        """ê²°ê³¼ ìœ íš¨ì„± ê²€ì¦"""
        try:
            # í™œì„± ìƒíƒœ í™•ì¸
            if not metadata.get('is_active', True):
                return False
            
            # ìœ íš¨ ê¸°ê°„ í™•ì¸
            valid_to = metadata.get('valid_to')
            if valid_to and valid_to != 'N/A':
                try:
                    end_date = datetime.fromisoformat(valid_to.replace('Z', '+00:00'))
                    if end_date < datetime.now():
                        return False
                except:
                    pass
            
            return True
            
        except Exception as e:
            
            return True  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ìœ íš¨í•˜ë‹¤ê³  ê°€ì •
    
    def _finalize_results(self, results: List[Dict], top_k: int) -> List[Dict]:
        """ìµœì¢… ê²°ê³¼ ì •ë¦¬"""
        try:
            # ì¤‘ë³µ ì œê±° (ë¸Œëœë“œ + ì œëª© ê¸°ì¤€)
            seen = set()
            unique_results = []
            
            for result in results:
                metadata = result.get('metadata', {})
                key = (metadata.get('brand', ''), metadata.get('title', ''))
                
                if key not in seen:
                    seen.add(key)
                    
                    # ìµœì¢… ê²°ê³¼ í¬ë§·íŒ…
                    formatted_result = {
                        "rank": len(unique_results) + 1,
                        "title": metadata.get('title', 'N/A'),
                        "brand": metadata.get('brand', 'N/A'),
                        "category": metadata.get('category', 'N/A'),
                        "benefit_type": metadata.get('benefit_type', 'N/A'),
                        "discount_rate": metadata.get('discount_rate', 'N/A'),
                        "conditions": metadata.get('conditions', 'N/A'),
                        "valid_from": metadata.get('valid_from', 'N/A'),
                        "valid_to": metadata.get('valid_to', 'N/A'),
                        "is_active": metadata.get('is_active', True),
                        "content": result.get('document', ''),
                        "similarity_score": result.get('similarity_score', 0),
                        "personalized_score": result.get('personalized_score', result.get('similarity_score', 0)),
                        "search_type": result.get('search_type', 'unknown'),
                        "potential_savings": result.get('potential_savings', 0)
                    }
                    
                    unique_results.append(formatted_result)
                    
                    if len(unique_results) >= top_k:
                        break
            
            return unique_results
            
        except Exception as e:
            
            return results[:top_k]
    
    def _get_search_strategy_info(self, categories: List[str], brands: List[str]) -> Dict[str, Any]:
        """ê²€ìƒ‰ ì „ëµ ì •ë³´ ë°˜í™˜"""
        return {
            "used_categories": categories,
            "used_brands": brands,
            "strategy": "hybrid" if (categories or brands) else "vector_only"
        }
    
    def _generate_error_response(self, error_msg: str, query: str = "") -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        return {
            "success": False,
            "query": query,
            "error": error_msg,
            "timestamp": datetime.now().isoformat()
        }


def initialize_rag_system():
    """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    global rag_system, config, database_connected
    
    if rag_system is None:
        try:
            # ì„¤ì • ë¡œë“œ
            config = get_ec2_config()
            
            # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            rag_system = EC2PersonalizedRAG(config)
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            database_connected = rag_system.connect_database()
            
            if database_connected:
                logger.info("ğŸ¯ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° DB ì—°ê²° ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ, DB ì—°ê²° ì‹¤íŒ¨ (ì œí•œëœ ê¸°ëŠ¥)")
                
        except Exception as e:

            # EC2ì—ì„œëŠ” ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚¤ì§€ ì•Šê³  ì œí•œëœ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘
            rag_system = None
    
    return rag_system
def create_sample_user_history() -> List[Dict]:
    """ìƒ˜í”Œ ì‚¬ìš©ì ì†Œë¹„ ì´ë ¥ ìƒì„±"""
    return [
        # ìµœê·¼ 1ì£¼ì¼ ì†Œë¹„ (ë†’ì€ ê°€ì¤‘ì¹˜)
        {"brand": "ìŠ¤íƒ€ë²…ìŠ¤", "category": "ì¹´í˜", "amount": 50000, "date": datetime.now() - timedelta(days=3)},
        {"brand": "ì´ë§ˆíŠ¸", "category": "ë§ˆíŠ¸", "amount": 150000, "date": datetime.now() - timedelta(days=5)},
        {"brand": "ì¿ íŒ¡", "category": "ì˜¨ë¼ì¸ì‡¼í•‘", "amount": 80000, "date": datetime.now() - timedelta(days=6)},
        
        # ì§€ë‚œ í•œë‹¬ ì†Œë¹„
        {"brand": "ìŠ¤íƒ€ë²…ìŠ¤", "category": "ì¹´í˜", "amount": 35000, "date": datetime.now() - timedelta(days=15)},
        {"brand": "ìŠ¤íƒ€ë²…ìŠ¤", "category": "ì¹´í˜", "amount": 42000, "date": datetime.now() - timedelta(days=20)},
        {"brand": "GS25", "category": "í¸ì˜ì ", "amount": 25000, "date": datetime.now() - timedelta(days=18)},
        {"brand": "ì˜¬ë¦¬ë¸Œì˜", "category": "ë·°í‹°", "amount": 120000, "date": datetime.now() - timedelta(days=25)},
        {"brand": "ë§¥ë„ë‚ ë“œ", "category": "ì‹ë‹¹", "amount": 15000, "date": datetime.now() - timedelta(days=28)},
        
        # ì§€ë‚œ 3ê°œì›” ì†Œë¹„ (ë‚®ì€ ê°€ì¤‘ì¹˜)
        {"brand": "ì´ë§ˆíŠ¸", "category": "ë§ˆíŠ¸", "amount": 200000, "date": datetime.now() - timedelta(days=40)},
        {"brand": "ìŠ¤íƒ€ë²…ìŠ¤", "category": "ì¹´í˜", "amount": 60000, "date": datetime.now() - timedelta(days=45)},
        {"brand": "í™ˆí”ŒëŸ¬ìŠ¤", "category": "ë§ˆíŠ¸", "amount": 180000, "date": datetime.now() - timedelta(days=50)},
        {"brand": "ì¿ íŒ¡", "category": "ì˜¨ë¼ì¸ì‡¼í•‘", "amount": 95000, "date": datetime.now() - timedelta(days=55)},
        {"brand": "CU", "category": "í¸ì˜ì ", "amount": 30000, "date": datetime.now() - timedelta(days=60)},
        {"brand": "ì§€ë§ˆì¼“", "category": "ì˜¨ë¼ì¸ì‡¼í•‘", "amount": 75000, "date": datetime.now() - timedelta(days=65)},
        {"brand": "ìŠ¤íƒ€ë²…ìŠ¤", "category": "ì¹´í˜", "amount": 38000, "date": datetime.now() - timedelta(days=70)},
        {"brand": "ì´ë””ì•¼", "category": "ì¹´í˜", "amount": 28000, "date": datetime.now() - timedelta(days=75)},
        {"brand": "KFC", "category": "ì‹ë‹¹", "amount": 22000, "date": datetime.now() - timedelta(days=80)},
        {"brand": "ì˜¨ëˆ„ë¦¬ì•½êµ­", "category": "ì˜ë£Œ", "amount": 45000, "date": datetime.now() - timedelta(days=85)},
    ]


class PersonalizedScoreCalculator:
    """ê°œì¸í™” ìŠ¤ì½”ì–´ ê³„ì‚°ê¸°"""
    
    @staticmethod
    def calculate_preference_score(brand: str, category: str, user_history: Dict) -> float:
        """ê°œì¸ ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° (0-1)"""
        brand_count = user_history.get('brand_counts', {}).get(brand, 0)
        category_count = user_history.get('category_counts', {}).get(category, 0) 
        total_transactions = user_history.get('total_transactions', 1)
        
        # ë¸Œëœë“œ ì„ í˜¸ë„ (ê°€ì¤‘ì¹˜ 70%)
        brand_preference = brand_count / total_transactions if total_transactions > 0 else 0
        
        # ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„ (ê°€ì¤‘ì¹˜ 30%)
        category_preference = category_count / total_transactions if total_transactions > 0 else 0
        
        return (brand_preference * 0.7) + (category_preference * 0.3)
    
    @staticmethod
    def calculate_potential_savings(benefit_type: str, discount_rate: float, 
                                  user_avg_spending: float) -> float:
        """ì˜ˆìƒ ì ˆê°ì•¡ ê³„ì‚° (ì› ë‹¨ìœ„)"""
        if benefit_type == "í• ì¸":
            return user_avg_spending * (discount_rate / 100)
        elif benefit_type == "ì ë¦½":
            return user_avg_spending * (discount_rate / 100) * 0.5  # ì ë¦½ì€ í• ì¸ì˜ 50% ê°€ì¹˜
        elif benefit_type == "ì¦ì •":
            return user_avg_spending * 0.2  # ì¦ì •í’ˆ ê°€ì¹˜ë¥¼ í‰ê·  ì†Œë¹„ì˜ 20%ë¡œ ê°€ì •
        else:
            return user_avg_spending * 0.1  # ê¸°íƒ€ í˜œíƒ
    
    @staticmethod
    def calculate_recency_weight(spending_date: datetime, current_date: datetime) -> float:
        """ìµœê·¼ì„± ê°€ì¤‘ì¹˜ ê³„ì‚° (0-1)"""
        days_diff = (current_date - spending_date).days
        if days_diff <= 7:
            return 1.0
        elif days_diff <= 30:
            return 0.8
        elif days_diff <= 90:
            return 0.5
        else:
            return 0.2


class EmbeddingExecutor:
    def __init__(self, host, api_key, request_id):
        self._host = host
        self._api_key = api_key
        self._request_id = request_id

    def execute(self, request_data):
        headers = {
            'Content-Type': 'application/json; charset=utf-8',
            'Authorization': self._api_key,
            'X-NCP-CLOVASTUDIO-REQUEST-ID': self._request_id
        }

        response = requests.post(
            f"https://{self._host}/v1/api-tools/embedding/clir-emb-dolphin",
            headers=headers,
            json=request_data
        )
        
        if response.status_code == 200:
            result = response.json()
            if result['status']['code'] == '20000':
                return result['result']['embedding']
        
        raise Exception(f"ì„ë² ë”© API ì˜¤ë¥˜: {response.status_code}")

     
class CompletionExecutor:
    def __init__(self, host, api_key, request_id):
        self._host = host
        self._api_key = api_key
        self._request_id = request_id

    def execute(self, completion_request):
        headers = {
            'Authorization': self._api_key,
            'X-NCP-CLOVASTUDIO-REQUEST-ID': self._request_id,
            'Content-Type': 'application/json; charset=utf-8',
            'Accept': 'text/event-stream'
        }

        final_answer = ""
        
        with requests.post(
            self._host + '/v3/chat-completions/HCX-005',
            headers=headers,
            json=completion_request,
            stream=True
        ) as r:
            for line in r.iter_lines():
                if line:
                    decoded_line = line.decode("utf-8")
                    
                    if decoded_line.startswith("data:"):
                        if decoded_line.endswith("[DONE]"):
                            break
                            
                        try:
                            json_str = decoded_line[5:]
                            event_data = json.loads(json_str)
                            
                            if (event_data.get('finishReason') == 'stop' and 
                                'message' in event_data and 
                                'content' in event_data['message']):
                                final_answer = event_data['message']['content']
                                break
                                
                        except json.JSONDecodeError:
                            continue
        
        return final_answer

class PerplexityAPI:
    def __init__(self, api_key=None):
        self.base_url = "https://api.perplexity.ai/chat/completions"
        self.api_key = api_key or self.get_api_key()
        
    def get_api_key(self):
        """API í‚¤ ì…ë ¥ë°›ê¸°"""
        api_key = os.getenv("PERPLEXITY_API_KEY")
        
        if not api_key:
            print("ğŸ’¡ Perplexity API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
            print("1. https://www.perplexity.ai/settings/api ì—ì„œ API í‚¤ ìƒì„±")
            print("2. Pro êµ¬ë…ìëŠ” ë§¤ì›” $5 í¬ë ˆë”§ ë¬´ë£Œ ì œê³µ")
            api_key = input("\nğŸ”‘ Perplexity API í‚¤: ").strip()
        
        return api_key
    
    def search(self, query, model="sonar", max_tokens=2000):
        """ì‹¤ì‹œê°„ ê²€ìƒ‰ ìˆ˜í–‰"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤
        models = {
            "sonar": "sonar",
            "sonar-pro": "sonar-pro",
            "online": "llama-3.1-sonar-large-128k-online",
            "chat": "llama-3.1-sonar-large-128k-chat"
        }
        
        data = {
            "model": models.get(model, "sonar"),
            "messages": [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì‹¤ì‹œê°„ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” AIì…ë‹ˆë‹¤. ìµœì‹  ì •ë³´ë¥¼ ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ì œê³µí•˜ê³ , ê°€ëŠ¥í•œ ê²½ìš° ì¶œì²˜ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user", 
                    "content": query
                }
            ],
            "max_tokens": max_tokens,
            "temperature": 0.2,
            "return_citations": True
        }
        
        try:
            response = requests.post(self.base_url, headers=headers, json=data)
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                
                return {
                    'success': True,
                    'content': content,
                    'usage': result.get('usage', {}),
                    'model': models.get(model, "sonar")
                }
            else:
                return {
                    'success': False,
                    'error': f"API ì˜¤ë¥˜ {response.status_code}: {response.text}"
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f"ìš”ì²­ ì˜¤ë¥˜: {str(e)}"
            }


class PerplexityAPI:
    """Perplexity API í´ë˜ìŠ¤ (ë‘ë²ˆì§¸ ì½”ë“œì—ì„œ ê°€ì ¸ì˜´)"""
    def __init__(self, api_key=None):
        self.base_url = "https://api.perplexity.ai/chat/completions"
        self.api_key = api_key or self.get_api_key()
        
    def get_api_key(self):
        """API í‚¤ ì…ë ¥ë°›ê¸°"""
        api_key = os.getenv("PERPLEXITY_API_KEY")
        
        if not api_key:
            print("ğŸ’¡ Perplexity API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
            print("1. https://www.perplexity.ai/settings/api ì—ì„œ API í‚¤ ìƒì„±")
            print("2. Pro êµ¬ë…ìëŠ” ë§¤ì›” $5 í¬ë ˆë”§ ë¬´ë£Œ ì œê³µ")
            api_key = input("\nğŸ”‘ Perplexity API í‚¤: ").strip()
        
        return api_key
    
    def search(self, query, model="sonar", max_tokens=2000):
        """ì‹¤ì‹œê°„ ê²€ìƒ‰ ìˆ˜í–‰"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤
        models = {
            "sonar": "sonar",
            "sonar-pro": "sonar-pro",
            "online": "llama-3.1-sonar-large-128k-online",
            "chat": "llama-3.1-sonar-large-128k-chat"
        }
        
        data = {
            "model": models.get(model, "sonar"),
            "messages": [
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì‹¤ì‹œê°„ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” AIì…ë‹ˆë‹¤. ìµœì‹  ì •ë³´ë¥¼ ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ì œê³µí•˜ê³ , ê°€ëŠ¥í•œ ê²½ìš° ì¶œì²˜ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user", 
                    "content": query
                }
            ],
            "max_tokens": max_tokens,
            "temperature": 0.2,
            "return_citations": True
        }
        
        try:
            response = requests.post(self.base_url, headers=headers, json=data)
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                
                return {
                    'success': True,
                    'content': content,
                    'usage': result.get('usage', {}),
                    'model': models.get(model, "sonar")
                }
            else:
                return {
                    'success': False,
                    'error': f"API ì˜¤ë¥˜ {response.status_code}: {response.text}"
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f"ìš”ì²­ ì˜¤ë¥˜: {str(e)}"
            }



class PersonalizedBenefitRAG:
    """ê°œì¸í™”ëœ í˜œíƒ ì¶”ì²œ RAG ì‹œìŠ¤í…œ (ë¸Œëœë“œ ì¸ì‹ ë° ê°œì¸í™” ìš”ì²­ ì²˜ë¦¬ ê°œì„ )"""
    
    def __init__(self, db_path="/opt/benefits-api/data/cafe_vector_db", collection_name="cafe_benefits"):
        self.db_path = db_path
        self.collection_name = collection_name
        self.client = None
        self.collection = None
        self.score_calculator = PersonalizedScoreCalculator()
        self.vector_space_type = "unknown"  # DBì—ì„œ ìë™ ê°ì§€
        
        # ğŸ” DB ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬ ìºì‹œ
        self.available_brands: Set[str] = set()
        self.available_categories: Set[str] = set()
        self.db_metadata_loaded = False
        
        # ğŸ”— Perplexity API ì¶”ê°€
        self.perplexity_api = None
        self._init_perplexity_api()
        
        # API ì‹¤í–‰ì ì´ˆê¸°í™”
        api_key = 'Bearer nv-53f7a8c4abe74e20ab90446ed46ba79fvozJ'
        
        self.embedding_executor = EmbeddingExecutor(
            host='clovastudio.stream.ntruss.com',
            api_key=api_key,
            request_id='93ae6593a47d4437b634f2cbc5282896'
        )
        
        self.completion_executor = CompletionExecutor(
            host="https://clovastudio.stream.ntruss.com",
            api_key=api_key,
            request_id='a8a2aebe279a445f8425e0e2aa8c118d'
        )

    def _init_perplexity_api(self):
        """ğŸ”— Perplexity API ì´ˆê¸°í™”"""
        try:
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ í™•ì¸
            api_key = os.getenv("PERPLEXITY_API_KEY")
            if api_key:
                self.perplexity_api = PerplexityAPI(api_key)
                print("ğŸ”— Perplexity API ì—°ê²° ì„±ê³µ")
            else:
                print("ğŸ’¡ Perplexity API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ PERPLEXITY_API_KEY ì„¤ì •í•˜ê±°ë‚˜ ë‚˜ì¤‘ì— ì…ë ¥í•˜ì„¸ìš”.")
        except Exception as e:
            print(f"âš ï¸ Perplexity API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.perplexity_api = None

    def _search_with_perplexity(self, query: str, brand: str = None) -> str:
        """ğŸ”— Perplexity APIë¡œ ì‹¤ì‹œê°„ ê²€ìƒ‰"""
        try:
            # APIê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™” ì‹œë„
            if not self.perplexity_api:
                try:
                    self.perplexity_api = PerplexityAPI()
                except:
                    return "âŒ Perplexity APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
            
            # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
            if brand:
                search_query = f"2025ë…„ 8ì›” í˜„ì¬ {brand} í• ì¸ í˜œíƒ ì´ë²¤íŠ¸ í”„ë¡œëª¨ì…˜ ì¿ í°"
            else:
                search_query = f"2025ë…„ 8ì›” í˜„ì¬ {query} í• ì¸ í˜œíƒ ì´ë²¤íŠ¸ í”„ë¡œëª¨ì…˜"
            
            print(f"ğŸ” Perplexity ê²€ìƒ‰ ì¤‘: {search_query}")
            
            # ì‹¤ì‹œê°„ ê²€ìƒ‰ ìˆ˜í–‰
            result = self.perplexity_api.search(search_query, model="sonar")  # sonar-pro ëŒ€ì‹  sonar ì‚¬ìš©
            
            if result['success']:
                content = result['content']
                
                # ê²°ê³¼ í¬ë§·íŒ…
                response = f"ğŸŒ ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼ (Perplexity):\n\n"
                response += content
                
                return response
            else:
                return f"âŒ ì‹¤ì‹œê°„ ê²€ìƒ‰ ì‹¤íŒ¨: {result['error']}"
                
        except Exception as e:
            return f"âŒ ì‹¤ì‹œê°„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}"

    def _extract_categories_from_query(self, query: str, debug: bool = False) -> List[str]:
        """ğŸ”§ ì¿¼ë¦¬ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
        
        if debug:
            print(f"ğŸ” ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ì‹œì‘: '{query}'")
        
        found_categories = []
        
        # í™•ì‹¤í•œ ì¹´í…Œê³ ë¦¬ íŒ¨í„´ ë§¤ì¹­
        known_category_patterns = {
            'ì¹´í˜': [r'ì¹´í˜', r'ì»¤í”¼', r'coffee', r'cafe', r'ì»¤í”¼ìˆ', r'ì»¤í”¼ì ', r'ì•„ë©”ë¦¬ì¹´ë…¸', r'ë¼ë–¼'],
            'ë§ˆíŠ¸': [r'ë§ˆíŠ¸', r'mart', r'ìŠˆí¼', r'ëŒ€í˜•ë§ˆíŠ¸', r'í• ì¸ë§ˆíŠ¸', r'ì‡¼í•‘ëª°', r'ìƒí•„í’ˆ'],
            'í¸ì˜ì ': [r'í¸ì˜ì ', r'í¸ì˜', r'ì»¨ë¹„ë‹ˆ', r'convenience'],
            'ì˜¨ë¼ì¸ì‡¼í•‘': [r'ì˜¨ë¼ì¸', r'ì‡¼í•‘', r'ì¸í„°ë„·', r'online', r'shopping', r'ì´ì»¤ë¨¸ìŠ¤', r'ë°°ì†¡'],
            'ì‹ë‹¹': [r'ì‹ë‹¹', r'ìŒì‹ì ', r'ë ˆìŠ¤í† ë‘', r'restaurant', r'ìŒì‹', r'ë¨¹ê±°ë¦¬', r'dining', r'ì¹˜í‚¨', r'ë²„ê±°', r'í–„ë²„ê±°'],
            'ë·°í‹°': [r'ë·°í‹°', r'í™”ì¥í’ˆ', r'ë¯¸ìš©', r'beauty', r'cosmetic', r'ìŠ¤í‚¨ì¼€ì–´', r'ë©”ì´í¬ì—…'],
            'ì˜ë£Œ': [r'ì˜ë£Œ', r'ì•½êµ­', r'ë³‘ì›', r'pharmacy', r'medical', r'health', r'ê±´ê°•', r'ì˜ì–‘ì œ', r'ë¹„íƒ€ë¯¼'],
            'êµí†µ': [r'êµí†µ', r'ì§€í•˜ì² ', r'ë²„ìŠ¤', r'íƒì‹œ', r'ì „ì² ', r'ëŒ€ì¤‘êµí†µ', r'metro', r'ì •ê¸°ê¶Œ']
        }
        
        query_lower = query.lower()
        
        # í™•ì‹¤í•œ ì¹´í…Œê³ ë¦¬ íŒ¨í„´ ë§¤ì¹­
        for category_name, patterns in known_category_patterns.items():
            for pattern in patterns:
                if re.search(pattern, query_lower, re.IGNORECASE):
                    found_categories.append(category_name)
                    if debug:
                        print(f"   âœ… ì¹´í…Œê³ ë¦¬ ë°œê²¬: '{category_name}' (íŒ¨í„´: {pattern})")
                    break
        
        # ì¤‘ë³µ ì œê±°
        unique_categories = list(set(found_categories))
        
        if debug:
            print(f"   ğŸ¯ ìµœì¢… ì¶”ì¶œëœ ì¹´í…Œê³ ë¦¬: {unique_categories}")
        
        return unique_categories

    def _try_direct_category_search(self, query: str, categories: List[str], top_k: int, debug: bool = False) -> List[Dict]:
        """ğŸ¯ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì§ì ‘ ê²€ìƒ‰ (ê°„ë‹¨ ë²„ì „)"""
        try:
            if debug:
                print(f"ğŸ¯ ì§ì ‘ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ì‹œë„: {categories}")
            
            all_results = []
            
            for category in categories:
                try:
                    category_results = self.collection.get(
                        where={"category": {"$eq": category}},
                        include=["metadatas", "documents"]
                    )
                    
                    if category_results and category_results.get('metadatas'):
                        for i, metadata in enumerate(category_results['metadatas']):
                            # ìœ íš¨ì„± ê²€ì¦
                            if self._validate_result(metadata, datetime.now()):
                                all_results.append({
                                    "id": f"direct_cat_{category}_{i}",
                                    "metadata": metadata,
                                    "distance": 0.0,  # ì§ì ‘ ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ì´ë¯€ë¡œ ìµœê³  ì ìˆ˜
                                    "document": category_results['documents'][i] if category_results.get('documents') else "",
                                    "vector_rank": i + 1
                                })
                    
                    if debug:
                        count = len(category_results['metadatas']) if category_results and category_results.get('metadatas') else 0
                        print(f"   '{category}': {count}ê°œ ê²°ê³¼")
                        
                except Exception as e:
                    if debug:
                        print(f"   '{category}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue
            
            # ê²°ê³¼ ì œí•œ
            if all_results:
                limited_results = all_results[:top_k]
                if debug:
                    print(f"ğŸ¯ ì§ì ‘ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ì„±ê³µ: {len(limited_results)}ê°œ ë°˜í™˜")
                return limited_results
            
            return []
            
        except Exception as e:
            if debug:
                print(f"âŒ ì§ì ‘ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    def calculate_vector_similarity_universal(self, distance: float, all_distances: List[float] = None) -> float:
        """ğŸ”§ ë§ŒëŠ¥ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚° (ìŒìˆ˜ ê±°ë¦¬ê°’ ì²˜ë¦¬)"""
        
        # ìŒìˆ˜ ê±°ë¦¬ê°’ ì²˜ë¦¬ (IP ë°©ì‹)
        if distance < 0:
            # Inner Product: ìŒìˆ˜ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ
            # -800ëŒ€ ê°’ì„ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
            if all_distances:
                min_dist = min(all_distances)
                max_dist = max(all_distances)
                range_dist = max_dist - min_dist
                
                if range_dist > 0:
                    # ìƒëŒ€ì  ìœ„ì¹˜ ê³„ì‚° (IPëŠ” ë†’ì„ìˆ˜ë¡ ìœ ì‚¬í•˜ë¯€ë¡œ ì—­ì „)
                    relative_pos = (distance - min_dist) / range_dist
                    similarity = 1 - relative_pos  # ë†’ì€ ê°’ = ë†’ì€ ìœ ì‚¬ë„
                else:
                    similarity = 0.5  # ëª¨ë‘ ë™ì¼í•˜ë©´ ì¤‘ê°„ê°’
            else:
                # ë‹¨ìˆœ ì •ê·œí™” (-1000 ~ -800 ë²”ìœ„ ê°€ì •)
                normalized = max(0, min(1, (distance + 1000) / 200))
                similarity = normalized
        
        # ì–‘ìˆ˜ ê±°ë¦¬ê°’ ì²˜ë¦¬ (cosine/l2 ë°©ì‹)
        else:
            if self.vector_space_type == "cosine":
                # Cosine ê±°ë¦¬: 0=ì¼ì¹˜, 2=ë°˜ëŒ€
                similarity = max(0, 1 - (distance / 2))
            elif self.vector_space_type == "l2":
                # L2 ê±°ë¦¬: 0=ì¼ì¹˜, sqrt(2)=ìµœëŒ€ (ì •ê·œí™”ëœ ë²¡í„°)
                similarity = max(0, 1 - (distance / 1.414))
            else:
                # ê¸°ë³¸ê°’
                similarity = max(0, 1 - distance)
        
        return max(0, min(similarity, 1))  # 0-1 ë²”ìœ„ ë³´ì¥
    
    def connect_database(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (ì½ê¸° ì „ìš©)"""
        try:
            if not os.path.exists(self.db_path):
                print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤: {self.db_path}")
                return False
            
            self.client = chromadb.PersistentClient(path=self.db_path)
            
            # ğŸ” ëª¨ë“  ì»¬ë ‰ì…˜ ì´ë¦„ í™•ì¸
            try:
                collections = self.client.list_collections()
                print(f"ğŸ” ë°œê²¬ëœ ì»¬ë ‰ì…˜ë“¤: {[c.name for c in collections]}")
                
                if collections:
                    # ì²« ë²ˆì§¸ ì»¬ë ‰ì…˜ ì‚¬ìš©
                    self.collection = collections[0]
                    self.collection_name = collections[0].name
                    print(f"âœ… ìë™ ì„ íƒëœ ì»¬ë ‰ì…˜: {self.collection_name}")
                else:
                    print("âŒ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
                    return False
                    
            except Exception as e:
                # ê¸°ì¡´ ë°©ì‹ ì‹œë„
                print(f"ì»¬ë ‰ì…˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨, ê¸°ë³¸ ì´ë¦„ìœ¼ë¡œ ì‹œë„: {e}")
                self.collection = self.client.get_collection(name=self.collection_name)
            
            # ë²¡í„° ê³µê°„ íƒ€ì… ê°ì§€
            metadata = self.collection.metadata
            self.vector_space_type = metadata.get("hnsw:space", "unknown")
            
            count = self.collection.count()
            print(f"âœ… RAG DB ì—°ê²° ì„±ê³µ (ì´ {count}ê°œ ë¬¸ì„œ, {self.vector_space_type.upper()} ê±°ë¦¬)")
            print("ğŸ”’ ì½ê¸° ì „ìš© ëª¨ë“œ - DB ìˆ˜ì •í•˜ì§€ ì•ŠìŒ")
            
            # ğŸ” DB ë©”íƒ€ë°ì´í„° ë¡œë“œ
            self._load_database_metadata()
            
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def _load_database_metadata(self) -> None:
        """ğŸ” DBì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬ ëª©ë¡ ë¡œë“œ"""
        try:
            print("ğŸ” DB ë©”íƒ€ë°ì´í„° ë¡œë”© ì¤‘...")
            
            # ëª¨ë“  ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ (ë²¡í„° ì—†ì´)
            all_results = self.collection.get(
                include=["metadatas"]
            )
            
            if not all_results or not all_results.get('metadatas'):
                print("âŒ DB ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
                return
            
            # ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
            for metadata in all_results['metadatas']:
                if metadata:
                    brand = metadata.get('brand')
                    category = metadata.get('category')
                    
                    if brand:
                        self.available_brands.add(brand.strip())
                    if category:
                        self.available_categories.add(category.strip())
            
            self.db_metadata_loaded = True
            
            print(f"âœ… DB ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
            print(f"   ğŸ“¦ ì‚¬ìš© ê°€ëŠ¥í•œ ë¸Œëœë“œ: {len(self.available_brands)}ê°œ")
            print(f"   ğŸ·ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬: {len(self.available_categories)}ê°œ")
            
            # ì£¼ìš” ë¸Œëœë“œ ë¯¸ë¦¬ë³´ê¸°
            if self.available_brands:
                sample_brands = list(self.available_brands)[:10]
                print(f"   ğŸ” ë¸Œëœë“œ ì˜ˆì‹œ: {', '.join(sample_brands)}")
            
        except Exception as e:
            print(f"âŒ DB ë©”íƒ€ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            self.db_metadata_loaded = False
    
    def _check_brand_existence(self, brands: List[str], debug: bool = False) -> Dict[str, bool]:
        """ğŸ” ë¸Œëœë“œê°€ DBì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        if not self.db_metadata_loaded:
            if debug:
                print("âš ï¸ DB ë©”íƒ€ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ - ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë¶ˆê°€")
            return {brand: True for brand in brands}  # ì•ˆì „í•˜ê²Œ í†µê³¼
        
        result = {}
        for brand in brands:
            # ì •í™•í•œ ë§¤ì¹­
            exact_match = brand in self.available_brands
            
            # ìœ ì‚¬í•œ ë¸Œëœë“œ ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ, ë¶€ë¶„ ë§¤ì¹­)
            similar_match = any(
                brand.lower() in available_brand.lower() or 
                available_brand.lower() in brand.lower()
                for available_brand in self.available_brands
            )
            
            exists = exact_match or similar_match
            result[brand] = exists
            
            if debug:
                status = "âœ… ì¡´ì¬" if exists else "âŒ ì—†ìŒ"
                print(f"   ğŸ” '{brand}': {status}")
        
        return result
    
    def _check_category_existence(self, categories: List[str], debug: bool = False) -> Dict[str, bool]:
        """ğŸ” ì¹´í…Œê³ ë¦¬ê°€ DBì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        if not self.db_metadata_loaded:
            if debug:
                print("âš ï¸ DB ë©”íƒ€ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ - ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë¶ˆê°€")
            return {category: True for category in categories}  # ì•ˆì „í•˜ê²Œ í†µê³¼
        
        result = {}
        for category in categories:
            # ì •í™•í•œ ë§¤ì¹­
            exact_match = category in self.available_categories
            
            # ìœ ì‚¬í•œ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
            similar_match = any(
                category.lower() in available_category.lower() or 
                available_category.lower() in category.lower()
                for available_category in self.available_categories
            )
            
            exists = exact_match or similar_match
            result[category] = exists
            
            if debug:
                status = "âœ… ì¡´ì¬" if exists else "âŒ ì—†ìŒ"
                print(f"   ğŸ” '{category}': {status}")
        
        return result
    
    
    def create_user_profile(self,user_spending_history: List[Dict]) -> Dict:
        """ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±"""
        profile = {
            'brand_counts': defaultdict(int),
            'category_counts': defaultdict(int),
            'brand_spending': defaultdict(float),
            'category_spending': defaultdict(float),
            'total_transactions': 0,
            'total_spending': 0.0,
            'recent_brands': [],  # ìµœê·¼ 1ì£¼ì¼
            'preferred_categories': [],
            'avg_spending_per_brand': {},
            'spending_timeline': []
        }
        
        current_date = datetime.now()
        recent_threshold = current_date - timedelta(days=7)
        
        for transaction in user_spending_history:
            brand = transaction['brand']
            category = transaction.get('category', 'Unknown')
            amount = transaction['amount']
            date = datetime.fromisoformat(transaction['date']) if isinstance(transaction['date'], str) else transaction['date']
            
            # ê¸°ë³¸ í†µê³„
            profile['brand_counts'][brand] += 1
            profile['category_counts'][category] += 1
            profile['brand_spending'][brand] += amount
            profile['category_spending'][category] += amount
            profile['total_transactions'] += 1
            profile['total_spending'] += amount
            
            # ìµœê·¼ ë¸Œëœë“œ (ê°€ì¤‘ì¹˜ ì ìš©)
            if date >= recent_threshold:
                recency_weight = self.score_calculator.calculate_recency_weight(date, current_date)
                profile['recent_brands'].append({
                    'brand': brand,
                    'category': category,
                    'amount': amount,
                    'weight': recency_weight,
                    'date': date
                })
            
            # ì‹œê°„ìˆœ ê¸°ë¡
            profile['spending_timeline'].append({
                'brand': brand,
                'category': category, 
                'amount': amount,
                'date': date
            })
        
        # ë¸Œëœë“œë³„ í‰ê·  ì†Œë¹„ì•¡ ê³„ì‚°
        for brand, total_amount in profile['brand_spending'].items():
            count = profile['brand_counts'][brand]
            profile['avg_spending_per_brand'][brand] = total_amount / count
        
        # ì„ í˜¸ ì¹´í…Œê³ ë¦¬ ì •ë ¬ (ì†Œë¹„ ë¹ˆë„ ê¸°ì¤€)
        profile['preferred_categories'] = sorted(
            profile['category_counts'].items(), 
            key=lambda x: x[1], 
            reverse=True
        )
        
        return dict(profile)  # defaultdictë¥¼ ì¼ë°˜ dictë¡œ ë³€í™˜

    def _is_personalization_query(self, query: str) -> bool:
        """ğŸ¯ ê°œì¸í™” ìš”ì²­ì¸ì§€ íŒë‹¨"""
        personalization_patterns = [
            # ëª…ì‹œì  ê°œì¸í™” ìš”ì²­
            r'ë‚´\s*ì†Œë¹„.*íŒ¨í„´', r'ë‚´.*ë§ëŠ”', r'ë‚˜.*ë§ëŠ”', r'ìš°ë¦¬.*ë§ëŠ”',
            r'ê°œì¸í™”.*ì¶”ì²œ', r'ë§ì¶¤.*ì¶”ì²œ', r'ë§ì¶¤í˜•.*í˜œíƒ',
            
            # ì†Œë¹„ ì´ë ¥ ê¸°ë°˜ ìš”ì²­
            r'ì§€ë‚œ.*ì†Œë¹„', r'ìµœê·¼.*ì†Œë¹„', r'ì €ë²ˆ.*ì†Œë¹„',
            r'ì§€ë‚œì£¼.*ì¼', r'ì €ë²ˆì£¼.*ì¼', r'ìµœê·¼.*ì¼',
            r'ë‚´ê°€.*ìì£¼', r'ë‚´ê°€.*ë§ì´', r'ë‚´ê°€.*ì£¼ë¡œ',
            
            # ì¼ë°˜ì ì¸ ì¶”ì²œ ìš”ì²­ (ë¸Œëœë“œ ì—†ì´)
            r'^(?!.*[ê°€-í£A-Za-z]{2,}\s*(í˜œíƒ|ì´ë²¤íŠ¸|í• ì¸)).*ì¶”ì²œ.*í•´.*ì¤˜',
            r'^(?!.*[ê°€-í£A-Za-z]{2,}\s*(í˜œíƒ|ì´ë²¤íŠ¸|í• ì¸)).*í˜œíƒ.*ìˆ.*ì–´',
            
            # íŒ¨í„´ ê¸°ë°˜ ìš”ì²­
            r'íŒ¨í„´.*ê¸°ë°˜', r'ì´ë ¥.*ê¸°ë°˜', r'íˆìŠ¤í† ë¦¬.*ê¸°ë°˜'
        ]
        
        for pattern in personalization_patterns:
            if re.search(pattern, query, re.IGNORECASE):
                return True
        
        return False
    def _try_direct_brand_search(self, query: str, top_k: int, debug: bool = False) -> List[Dict]:
        """ğŸ¯ ë¸Œëœë“œ ê¸°ë°˜ ì§ì ‘ ê²€ìƒ‰ (ë²¡í„° ê²€ìƒ‰ ì „ì— ì‹œë„)"""
        try:
            # ì¿¼ë¦¬ì—ì„œ ë¸Œëœë“œ ì¶”ì¶œ
            extracted_brands = self._extract_brands_from_query(query, debug)
            
            if not extracted_brands:
                return []
            
            if debug:
                print(f"ğŸ¯ ì§ì ‘ ë¸Œëœë“œ ê²€ìƒ‰ ì‹œë„: {extracted_brands}")
            
            # ê° ë¸Œëœë“œë³„ë¡œ ì§ì ‘ ê²€ìƒ‰
            all_results = []
            
            for brand in extracted_brands:
                # DBì—ì„œ í•´ë‹¹ ë¸Œëœë“œ ì§ì ‘ ì°¾ê¸°
                try:
                    brand_results = self.collection.get(
                        where={"brand": {"$eq": brand}},
                        include=["metadatas", "documents"]
                    )
                    
                    if brand_results and brand_results.get('metadatas'):
                        for i, metadata in enumerate(brand_results['metadatas']):
                            # ìœ íš¨ì„± ê²€ì¦
                            if self._validate_result(metadata, datetime.now()):
                                all_results.append({
                                    "id": f"direct_{brand}_{i}",
                                    "metadata": metadata,
                                    "distance": 0.0,  # ì§ì ‘ ë§¤ì¹­ì´ë¯€ë¡œ ìµœê³  ì ìˆ˜
                                    "document": brand_results['documents'][i] if brand_results.get('documents') else "",
                                    "vector_rank": i + 1
                                })
                    
                    if debug:
                        count = len(brand_results['metadatas']) if brand_results and brand_results.get('metadatas') else 0
                        print(f"   '{brand}': {count}ê°œ ê²°ê³¼")
                        
                except Exception as e:
                    if debug:
                        print(f"   '{brand}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue
            
            # ê²°ê³¼ ì œí•œ
            if all_results:
                limited_results = all_results[:top_k]
                if debug:
                    print(f"ğŸ¯ ì§ì ‘ ë¸Œëœë“œ ê²€ìƒ‰ ì„±ê³µ: {len(limited_results)}ê°œ ë°˜í™˜")
                return limited_results
            
            return []
            
        except Exception as e:
            if debug:
                print(f"âŒ ì§ì ‘ ë¸Œëœë“œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def _fallback_text_search(self, query: str, filters: Dict, top_k: int, debug: bool = False) -> List[Dict]:
        """ğŸ”„ í…ìŠ¤íŠ¸ ê¸°ë°˜ í´ë°± ê²€ìƒ‰ (ê°œì„ ëœ ë²„ì „)"""
        try:
            if debug:
                print("ğŸ”„ í…ìŠ¤íŠ¸ í´ë°± ê²€ìƒ‰ ì‹œì‘...")
            
            # ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
            all_results = self.collection.get(
                include=["metadatas", "documents"]
            )
            
            if not all_results or not all_results.get('metadatas'):
                print("âŒ DBì— ë°ì´í„° ì—†ìŒ")
                return []
            
            # í…ìŠ¤íŠ¸ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
            scored_results = []
            query_lower = query.lower()
            query_words = query_lower.split()
            
            for i, metadata in enumerate(all_results['metadatas']):
                if not metadata:
                    continue
                
                # ìœ íš¨ì„± ê²€ì¦
                if not self._validate_result(metadata, datetime.now()):
                    continue
                
                # í…ìŠ¤íŠ¸ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
                score = 0.0
                
                # ë¸Œëœë“œ ë§¤ì¹­ (ê°€ì¥ ì¤‘ìš” - 60%)
                brand = metadata.get('brand', '').lower()
                if brand:
                    if brand in query_lower:
                        score += 0.6
                    elif any(word in brand for word in query_words):
                        score += 0.4
                    elif any(brand in word for word in query_words):
                        score += 0.3
                
                # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ (20%)
                category = metadata.get('category', '').lower()
                if category and category in query_lower:
                    score += 0.2
                
                # ì œëª© ë§¤ì¹­ (15%)
                title = metadata.get('title', '').lower()
                if title:
                    matching_words = sum(1 for word in query_words if word in title)
                    score += 0.15 * (matching_words / len(query_words))
                
                # í˜œíƒ íƒ€ì… ë§¤ì¹­ (5%)
                benefit_type = metadata.get('benefit_type', '').lower()
                benefit_keywords = ['í• ì¸', 'ì ë¦½', 'ì¿ í°', 'í˜œíƒ', 'ì´ë²¤íŠ¸', 'ì¦ì •']
                if any(keyword in query_lower for keyword in benefit_keywords):
                    if benefit_type in query_lower:
                        score += 0.05
                
                if score > 0:
                    scored_results.append({
                        "id": f"text_match_{i}",
                        "metadata": metadata,
                        "distance": 1.0 - score,  # ì ìˆ˜ë¥¼ ê±°ë¦¬ë¡œ ë³€í™˜
                        "document": all_results['documents'][i] if all_results.get('documents') else "",
                        "vector_rank": 0,
                        "text_score": score
                    })
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            scored_results.sort(key=lambda x: x['text_score'], reverse=True)
            
            # ìƒìœ„ ê²°ê³¼ë§Œ ë°˜í™˜
            final_results = scored_results[:top_k]
            
            if debug:
                print(f"ğŸ”„ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)}ê°œ ê²°ê³¼")
                for i, result in enumerate(final_results[:3]):
                    brand = result['metadata'].get('brand', 'Unknown')
                    score = result.get('text_score', 0)
                    print(f"   [{i+1}] {brand}: ì ìˆ˜ {score:.3f}")
            
            return final_results
            
        except Exception as e:
            if debug:
                print(f"âŒ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    def _extract_brands_from_query(self, query: str, debug: bool = False) -> List[str]:
        """ğŸ”§ ê°œì„ ëœ ë¸Œëœë“œ ì¶”ì¶œ (ì •í™•ë„ í–¥ìƒ)"""
        
        if debug:
            print(f"ğŸ” ë¸Œëœë“œ ì¶”ì¶œ ì‹œì‘: '{query}'")
        
        found_brands = []
        
        # 1ë‹¨ê³„: í™•ì‹¤í•œ ë¸Œëœë“œ íŒ¨í„´ ë§¤ì¹­ (í•œêµ­ ìœ ëª… ë¸Œëœë“œë“¤)
        known_brand_patterns = {
            # ì¹´í˜/ìŒì‹
            'ìŠ¤íƒ€ë²…ìŠ¤': [r'ìŠ¤íƒ€ë²…ìŠ¤', r'starbucks'],
            'ì´ë””ì•¼': [r'ì´ë””ì•¼', r'ediya'],
            'íˆ¬ì¸í”Œë ˆì´ìŠ¤': [r'íˆ¬ì¸', r'íˆ¬ì¸í”Œë ˆì´ìŠ¤', r'twosome'],
            'ë§¥ë„ë‚ ë“œ': [r'ë§¥ë„ë‚ ë“œ', r'ë§¥ë‚ ', r'mcdonald'],
            'ë²„ê±°í‚¹': [r'ë²„ê±°í‚¹', r'burgerking'],
            'KFC': [r'kfc', r'ì¼€ì´ì—í”„ì”¨'],
            
            # ë§ˆíŠ¸/ì‡¼í•‘
            'ì´ë§ˆíŠ¸': [r'ì´ë§ˆíŠ¸', r'emart'],
            'í™ˆí”ŒëŸ¬ìŠ¤': [r'í™ˆí”ŒëŸ¬ìŠ¤', r'homeplus'],
            'ë¡¯ë°ë§ˆíŠ¸': [r'ë¡¯ë°ë§ˆíŠ¸', r'lotte'],
            'ì¿ íŒ¡': [r'ì¿ íŒ¡', r'coupang'],
            'ì§€ë§ˆì¼“': [r'ì§€ë§ˆì¼“', r'gmarket'],
            '11ë²ˆê°€': [r'11ë²ˆê°€', r'ì‹­ì¼ë²ˆê°€'],
            
            # í¸ì˜ì 
            'GS25': [r'gs25', r'ì§€ì—ìŠ¤'],
            'CU': [r'cu', r'ì”¨ìœ '],
            'ì„¸ë¸ì¼ë ˆë¸': [r'ì„¸ë¸ì¼ë ˆë¸', r'7-eleven', r'ì„¸ë¸'],
            'ì´ë§ˆíŠ¸24': [r'ì´ë§ˆíŠ¸24', r'ì´ë§ˆíŠ¸ì´ì‹­ì‚¬'],
            
            # ë·°í‹°/ê¸°íƒ€
            'ì˜¬ë¦¬ë¸Œì˜': [r'ì˜¬ë¦¬ë¸Œì˜', r'oliveyoung'],
            'ë„¤ì´ë²„': [r'ë„¤ì´ë²„', r'naver'],
            'ì¹´ì¹´ì˜¤': [r'ì¹´ì¹´ì˜¤', r'kakao'],
            'ì‚¼ì„±': [r'ì‚¼ì„±', r'samsung'],
            'ì• í”Œ': [r'ì• í”Œ', r'apple'],  # ğŸ”§ ì• í”Œ ì¶”ê°€
            'LG': [r'lg', r'ì—˜ì§€'],
            'í˜„ëŒ€': [r'í˜„ëŒ€', r'hyundai']
        }
        
        query_lower = query.lower()
        
        # í™•ì‹¤í•œ ë¸Œëœë“œ íŒ¨í„´ ë§¤ì¹­
        for brand_name, patterns in known_brand_patterns.items():
            for pattern in patterns:
                if re.search(pattern, query_lower, re.IGNORECASE):
                    found_brands.append(brand_name)
                    if debug:
                        print(f"   âœ… í™•ì‹¤í•œ ë¸Œëœë“œ ë°œê²¬: '{brand_name}' (íŒ¨í„´: {pattern})")
                    break
        
        # 2ë‹¨ê³„: ğŸ”§ ë” ì—„ê²©í•œ ì¼ë°˜ ë¸Œëœë“œëª… ì¶”ì¶œ
        # í™•ì‹¤í•œ ë¸Œëœë“œê°€ ì—†ì„ ë•Œë§Œ ì¼ë°˜ ì¶”ì¶œ ì‹œë„
        if not found_brands:
            # ğŸ”§ ë¸Œëœë“œ í›„ë³´ ì¡°ê±´ì„ ë” ì—„ê²©í•˜ê²Œ
            words = query.split()
            for word in words:
                # ëª…í™•í•œ ë¸Œëœë“œëª… íŠ¹ì§•ì„ ê°€ì§„ ë‹¨ì–´ë§Œ
                if self._is_potential_brand_name(word):
                    # ğŸ”§ í™•ì¥ëœ ì¼ë°˜ ë‹¨ì–´ í•„í„°ë§
                    if not self._is_common_word(word):
                        found_brands.append(word)
                        if debug:
                            print(f"   ğŸ¤” ì ì¬ì  ë¸Œëœë“œ: '{word}'")
        
        # ì¤‘ë³µ ì œê±°
        unique_brands = list(set(found_brands))
        
        if debug:
            print(f"   ğŸ¯ ìµœì¢… ì¶”ì¶œëœ ë¸Œëœë“œ: {unique_brands}")
        
        return unique_brands

    def _is_potential_brand_name(self, word: str) -> bool:
        """ğŸ”§ ì ì¬ì  ë¸Œëœë“œëª…ì¸ì§€ íŒë‹¨ (ë” ì—„ê²©í•˜ê²Œ)"""
        # í•œê¸€ ë¸Œëœë“œ: 2-6ì (ë” ì—„ê²©í•˜ê²Œ)
        if re.match(r'^[ê°€-í£]{2,6}$', word):
            return True
        
        # ì˜ë¬¸ ë¸Œëœë“œ: ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ê±°ë‚˜ ì „ì²´ ëŒ€ë¬¸ì, 3-12ì
        if re.match(r'^[A-Z][a-zA-Z]{2,11}$', word) or re.match(r'^[A-Z]{2,8}$', word):
            return True
        
        return False

    def _is_common_word(self, word: str) -> bool:
        """ğŸ”§ ì¼ë°˜ ë‹¨ì–´ì¸ì§€ íŒë‹¨ (í™•ì¥ëœ í•„í„°ë§)"""
        common_words = {
            # ê¸°ë³¸ ë‹¨ì–´ë“¤
            'í˜œíƒ', 'í• ì¸', 'ì´ë²¤íŠ¸', 'ì¿ í°', 'ì ë¦½', 'ì¦ì •', 'ì„¸ì¼', 'íŠ¹ê°€', 'ì¶”ì²œ', 'ì°¾ì•„', 'ì•Œë ¤', 'ìˆì–´', 'í•´ì¤˜',
            
            # ì¥ì†Œ/ì¹´í…Œê³ ë¦¬
            'ì¹´í˜', 'ë§ˆíŠ¸', 'ì‹ë‹¹', 'í¸ì˜ì ', 'ì˜¨ë¼ì¸', 'ì‡¼í•‘', 'ë·°í‹°', 'ì˜ë£Œ', 'ë³‘ì›', 'ì•½êµ­', 'ì€í–‰', 'ê¸ˆìœµ',
            
            # ì„¤ëª… ë‹¨ì–´ë“¤
            'ì†Œë¹„', 'íŒ¨í„´', 'ë§ëŠ”', 'ì–´ë””', 'ë­ê°€', 'ì–´ë–¤', 'ì¢‹ì€', 'ê´œì°®ì€', 'ì €ë ´í•œ', 'ë¹„ì‹¼', 'ìµœê³ ', 'ì¸ê¸°',
            
            # ëŒ€ëª…ì‚¬/ì§€ì‹œì–´
            'ë‚´ê°€', 'ìš°ë¦¬', 'ì‚¬ëŒ', 'ê³ ê°', 'íšŒì›', 'ê°€ê²©', 'ëˆ', 'ì›', 'ë§Œì›', 'ì²œì›', 'ì •ë„', 'ì •ë§', 'ì§„ì§œ',
            
            # ë¶€ì‚¬/ì ‘ì†ì‚¬
            'ê·¸ëƒ¥', 'ì¢€', 'ì¡°ê¸ˆ', 'ë§ì´', 'ìì£¼', 'ê°€ë”', 'í•­ìƒ', 'ë³´í†µ', 'ìµœê·¼', 'ìš”ì¦˜', 'ì˜¤ëŠ˜', 'ì–´ì œ', 'ë‚´ì¼',
            
            # ì‹œê°„ ê´€ë ¨
            'ì§€ê¸ˆ', 'í˜„ì¬', 'ì´ë²ˆ', 'ë‹¤ìŒ', 'ì €ë²ˆ', 'ì˜¬í•´', 'ì‘ë…„', 'ë‚´ë…„', 'ì›”', 'ì¼', 'ì£¼', 'ë•Œë¬¸', 'ìœ„í•´',
            
            # ë™ì‚¬/í˜•ìš©ì‚¬ ì–´ê°„
            'í†µí•´', 'ëŒ€í•´', 'ê´€ë ¨', 'ê´€í•œ', 'ê°€ëŠ¥', 'ë¶ˆê°€ëŠ¥', 'í•„ìš”', 'ì¤‘ìš”', 'ìœ ìš©', 'í¸ë¦¬', 'ê°„ë‹¨', 'ë³µì¡',
            
            # ğŸ”§ ìƒˆë¡œ ì¶”ê°€ëœ í•„í„°ë§ ë‹¨ì–´ë“¤
            'ì•Œë ¤ì¤˜', 'í•´ì¤˜', 'ë³´ì—¬ì¤˜', 'ì°¾ì•„ì¤˜', 'ì¶”ì²œí•´ì¤˜', 'ë§í•´ì¤˜',
            'íŒ¨í„´ì—', 'ì†Œë¹„ì—', 'ì´ë ¥ì—', 'ê¸°ë°˜ì—', 'ë§ê²Œ', 'ë”°ë¼',
            'ì–´ë–»ê²Œ', 'ì–´ë””ì„œ', 'ì–¸ì œ', 'ì™œ', 'ë¬´ì—‡', 'ëˆ„êµ¬',
            'ìˆë‚˜', 'ìˆì–´', 'ì—†ì–´', 'ëì–´', 'ì¢‹ì•„', 'ì‹«ì–´'
        }
        
        return word in common_words
    
    def search_personalized_benefits(self, query: str, user_profile: Dict, 
                                top_k: int = 10, debug: bool = False) -> str:
        """ğŸ”— ê°œì¸í™”ëœ í˜œíƒ ê²€ìƒ‰ ë° ì¶”ì²œ (Perplexity API ì—°ë™)"""
        if debug:
            logger.info(f"ğŸ¯ ê°œì„ ëœ ê°œì¸í™” ê²€ìƒ‰ ì‹œì‘: {query}")
            # print(f"ğŸ‘¤ ì‚¬ìš©ì í”„ë¡œí•„: ì´ {user_profile['total_transactions']}ê±´, {user_profile['total_spending']:,.0f}ì›")
        
        # ğŸ”§ 1ë‹¨ê³„: ê°œì¸í™” ìš”ì²­ì¸ì§€ ë¨¼ì € í™•ì¸
        is_personalization = self._is_personalization_query(query)
        if debug:
            logger.info(f"ğŸ¯ ê°œì¸í™” ìš”ì²­ ì—¬ë¶€: {is_personalization}")
        
        # 2ë‹¨ê³„: ì¿¼ë¦¬ ë¶„ì„
        analysis = MultiCategoryQueryParser.analyze_query_intent(query)
        filters, parsed_info = MultiCategoryQueryParser.build_multi_category_filters(query, debug)
        logger.info(f"ğŸ”§ 2ë‹¨ê³„: ì¿¼ë¦¬ ë¶„ì„: {analysis}")
        logger.info(f"ğŸ”§ 2ë‹¨ê³„: ì¿¼ë¦¬ ë¶„ì„: {filters}")
        logger.info(f"ğŸ”§ 2ë‹¨ê³„: ì¿¼ë¦¬ ë¶„ì„: {parsed_info}")
        
        # ğŸ”§ 3ë‹¨ê³„: ê°œì„ ëœ ë¸Œëœë“œ ì¶”ì¶œ
        extracted_brands = self._extract_brands_from_query(query, debug)
        logger.info(f"ğŸ”§ 3ë‹¨ê³„: ê°œì„ ëœ ë¸Œëœë“œ ì¶”ì¶œ: {extracted_brands}")
        # ğŸ”§ 4ë‹¨ê³„: ê°œì„ ëœ ê²€ì¦ ë¡œì§ (ë” ê´€ëŒ€í•˜ê²Œ)
        validation_result = self._validate_query_improved(
            query, analysis, parsed_info, extracted_brands, is_personalization, debug
        )
        logger.info(f"ğŸ”§ 4ë‹¨ê³„: ê°œì„ ëœ ê²€ì¦ ë¡œì§: {validation_result}")
        # ğŸ”— 4.5ë‹¨ê³„: DBì— ë¸Œëœë“œê°€ ì—†ê±°ë‚˜ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° Perplexity API ì‚¬ìš©
        if not validation_result['valid']:
            # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¸Œëœë“œì— ëŒ€í•œ ì‹¤ì‹œê°„ ê²€ìƒ‰
            if extracted_brands:
                brand_name = extracted_brands[0]  # ì²« ë²ˆì§¸ ë¸Œëœë“œ
                logger.info(f"ğŸ”— DBì— '{brand_name}' ë¸Œëœë“œê°€ ì—†ì–´ ì‹¤ì‹œê°„ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤...")
                return self._search_with_perplexity(query, brand_name)
            else:
                return validation_result['message']
        
        # ğŸ”§ 5ë‹¨ê³„: ê²€ìƒ‰ ì¿¼ë¦¬ ì¤€ë¹„ (í•„í„° ì¡°ê±´ ì™„í™”)
        search_query = query
        logger.info(f"ğŸ”§ 5ë‹¨ê³„: ê²€ìƒ‰ ì¿¼ë¦¬ ì¤€ë¹„: {search_query}")
        search_filters = {}  # í•„í„° ì¡°ê±´ ì™„í™” ë˜ëŠ” ì œê±°
        
        if is_personalization and not extracted_brands:
            # ê°œì¸í™” ìš”ì²­ì´ë©´ ì‚¬ìš©ì ì„ í˜¸ ë¸Œëœë“œ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ í™•ì¥
            enhanced_query = self._enhance_query_for_personalization(query, user_profile)
            if debug:
                logger.info(f"ğŸ¯ ê°œì¸í™” ì¿¼ë¦¬ í™•ì¥: '{enhanced_query}'")
            search_query = enhanced_query
        logger.info(f"ğŸ”§ 6ë‹¨ê³„: ê°œì„ ëœ ë²¡í„° ê²€ìƒ‰: {search_query}")
        # 6ë‹¨ê³„: ê°œì„ ëœ ë²¡í„° ê²€ìƒ‰ (ì§ì ‘ ë¸Œëœë“œ ê²€ìƒ‰ í¬í•¨)
        base_results = self._execute_vector_search_readonly(search_query, search_filters, top_k * 2, debug)
        
        # ğŸ”— 6.5ë‹¨ê³„: DBì—ì„œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ Perplexity API ì‚¬ìš©
        if not base_results:
            logger.info("ğŸ”— DBì—ì„œ ê²°ê³¼ê°€ ì—†ì–´ ì‹¤ì‹œê°„ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            if extracted_brands:
                return self._search_with_perplexity(query, extracted_brands[0])
            else:
                return self._search_with_perplexity(query)
        
        # 7ë‹¨ê³„: ê°œì¸í™” ìŠ¤ì½”ì–´ë§
        personalized_results = self._apply_personalization_scoring_readonly(
            base_results, user_profile, parsed_info, debug
        )
        logger.info(f"ğŸ”§ 7ë‹¨ê³„: ê°œì¸í™” ìŠ¤ì½”ì–´ë§: {personalized_results}")
        # 8ë‹¨ê³„: ìµœì¢… ì •ë ¬ ë° ì„ íƒ
        final_results = self._rank_and_select_results(
            personalized_results, user_profile, top_k, debug
        )
        logger.info(f"ğŸ”§ 8ë‹¨ê³„: ìµœì¢… ì •ë ¬ ë° ì„ íƒ: {final_results}")
        if debug:
            logger.info(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(base_results)}ê°œ â†’ ê°œì¸í™” í›„: {len(final_results)}ê°œ")
        
        # 9ë‹¨ê³„: ê²°ê³¼ ì¶œë ¥
        if not final_results:
            # ğŸ”— ìµœì¢…ì ìœ¼ë¡œë„ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ Perplexity API ì‚¬ìš©
            logger.info("ğŸ”— ìµœì¢… ê²°ê³¼ê°€ ì—†ì–´ ì‹¤ì‹œê°„ ê²€ìƒ‰ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            if extracted_brands:
                return self._search_with_perplexity(query, extracted_brands[0])
            else:
                return self._search_with_perplexity(query)
        logger.info(f"ğŸ”§ 9ë‹¨ê³„: ê²°ê³¼ ì¶œë ¥: {final_results}")
        return self._generate_results_readonly(final_results, user_profile, parsed_info)

    def _enhance_query_for_personalization(self, query: str, user_profile: Dict) -> str:
        """ğŸ¯ ê°œì¸í™” ìš”ì²­ì„ ìœ„í•œ ì¿¼ë¦¬ í™•ì¥"""
        # ì‚¬ìš©ì ìµœë‹¤ ì´ìš© ë¸Œëœë“œ 3ê°œ ì¶”ê°€
        top_brands = sorted(
            user_profile.get('brand_counts', {}).items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:3]
        
        # ì‚¬ìš©ì ìµœë‹¤ ì´ìš© ì¹´í…Œê³ ë¦¬ 2ê°œ ì¶”ê°€
        top_categories = user_profile.get('preferred_categories', [])[:2]
        
        enhanced_parts = [query]
        
        if top_brands:
            brand_names = [brand for brand, _ in top_brands]
            enhanced_parts.append(' '.join(brand_names))
        
        if top_categories:
            category_names = [category for category, _ in top_categories]
            enhanced_parts.append(' '.join(category_names))
        
        enhanced_parts.append('í˜œíƒ í• ì¸ ì´ë²¤íŠ¸ ì¶”ì²œ')
        
        return ' '.join(enhanced_parts)

    def _validate_query_improved(self, query: str, analysis: Dict, parsed_info: Dict, 
                               extracted_brands: List[str], is_personalization: bool, debug: bool) -> Dict[str, Any]:
        """ğŸ”§ ê°œì„ ëœ ì¿¼ë¦¬ ê²€ì¦ (ë¸Œëœë“œ ì¸ì‹ ë° ê°œì¸í™” ìš”ì²­ ì²˜ë¦¬ ê°œì„ )"""
        
        if debug:
            logger.info("ğŸ”§ ê°œì„ ëœ ì¿¼ë¦¬ ê²€ì¦ ì‹œì‘...")
            logger.info(f"   ğŸ¯ ê°œì¸í™” ìš”ì²­: {is_personalization}")
            logger.info(f"   ğŸª ì¶”ì¶œëœ ë¸Œëœë“œ: {extracted_brands}")
        
        # ğŸ¯ 1) ê°œì¸í™” ìš”ì²­ì´ë©´ ë¬´ì¡°ê±´ í†µê³¼
        if is_personalization:
            if debug:
                logger.info("   âœ… ê°œì¸í™” ìš”ì²­ìœ¼ë¡œ ì¸ì‹ - ê²€ìƒ‰ ì§„í–‰")
            return {'valid': True}
        
        # 2) ëª…ì‹œì  ì†Œë¹„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¸Œëœë“œ ì¡´ì¬ í™•ì¸
        if parsed_info.get('spending_data'):
            brands = list(parsed_info['spending_data'].keys())
            brand_existence = self._check_brand_existence(brands, debug)
            
            missing_brands = [brand for brand, exists in brand_existence.items() if not exists]
            if missing_brands:
                if debug:
                    print(f"   âŒ ì†Œë¹„ ë°ì´í„°ì˜ ë¸Œëœë“œ '{', '.join(missing_brands)}'ê°€ DBì— ì—†ìŒ")
                return {
                    'valid': False,
                    'message': self._generate_missing_brands_message(missing_brands, 'spending_data')
                }
            
            if debug:
                print("   âœ… ì†Œë¹„ ë°ì´í„°ì˜ ëª¨ë“  ë¸Œëœë“œê°€ DBì— ì¡´ì¬ - ê²€ìƒ‰ ì§„í–‰")
            return {'valid': True}
        
        # ğŸ”§ 3) ì¶”ì¶œëœ ë¸Œëœë“œê°€ ìˆì„ ë•Œë§Œ ì¡´ì¬ í™•ì¸
        if extracted_brands:
            brand_existence = self._check_brand_existence(extracted_brands, debug)
            missing_brands = [brand for brand, exists in brand_existence.items() if not exists]
            
            # ğŸ”§ ëª¨ë“  ë¸Œëœë“œê°€ ì—†ì„ ë•Œë§Œ ì°¨ë‹¨ (Perplexityë¡œ ë„˜ê¹€)
            if missing_brands and len(missing_brands) == len(extracted_brands):
                if debug:
                    print(f"   âŒ ì¶”ì¶œëœ ëª¨ë“  ë¸Œëœë“œ '{', '.join(missing_brands)}'ê°€ DBì— ì—†ìŒ - Perplexityë¡œ ì „í™˜")
                return {
                    'valid': False,
                    'message': f"ë¸Œëœë“œ '{', '.join(missing_brands)}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤."
                }
            elif missing_brands:
                if debug:
                    existing_brands = [b for b in extracted_brands if b not in missing_brands]
                    print(f"   âš ï¸ ì¼ë¶€ ë¸Œëœë“œë§Œ ì¡´ì¬: ì¡´ì¬={existing_brands}, ì—†ìŒ={missing_brands}")
                    print("   âœ… ì¡´ì¬í•˜ëŠ” ë¸Œëœë“œ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰ ì§„í–‰")
            else:
                if debug:
                    print("   âœ… ì¶”ì¶œëœ ëª¨ë“  ë¸Œëœë“œê°€ DBì— ì¡´ì¬ - ê²€ìƒ‰ ì§„í–‰")
            return {'valid': True}
        
        # 4) í˜œíƒ í‚¤ì›Œë“œë‚˜ ì¼ë°˜ì ì¸ ì¶”ì²œ ìš”ì²­ì´ë©´ í•­ìƒ í†µê³¼
        benefit_keywords = ['í˜œíƒ', 'í• ì¸', 'ì´ë²¤íŠ¸', 'ì ë¦½', 'ì¿ í°', 'ì¦ì •', 'íŠ¹ê°€', 'ì„¸ì¼', 'ì¶”ì²œ']
        general_keywords = ['ë§ëŠ”', 'íŒ¨í„´', 'ì†Œë¹„', 'ë‚´', 'ìš°ë¦¬', 'ì¢‹ì€', 'ê´œì°®ì€', 'ì–´ë–¤', 'ë­ê°€']
        
        has_benefit_keyword = any(keyword in query for keyword in benefit_keywords)
        has_general_keyword = any(keyword in query for keyword in general_keywords)
        
        if has_benefit_keyword or has_general_keyword:
            if debug:
                if has_benefit_keyword:
                    print("   âœ… í˜œíƒ í‚¤ì›Œë“œ ì¸ì‹ë¨ - ì¼ë°˜ ê²€ìƒ‰ ì§„í–‰")
                if has_general_keyword:
                    print("   âœ… ì¼ë°˜ ì¶”ì²œ ìš”ì²­ ì¸ì‹ë¨ - ê²€ìƒ‰ ì§„í–‰")
            return {'valid': True}
        
        # 5) ë¹ˆ ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬ë„ í†µê³¼ (ì‚¬ìš©ìê°€ ëª¨ë¥´ê³  ë¬¼ì–´ë³¼ ìˆ˜ ìˆìŒ)
        if debug:
            print("   âœ… ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬ ì—†ëŠ” ì¼ë°˜ ì§ˆë¬¸ - ì „ì²´ ê²€ìƒ‰ ì§„í–‰")
        return {'valid': True}

    def _execute_vector_search_readonly(self, query: str, filters: Dict, top_k: int, debug: bool = False) -> List[Dict]:
        """ğŸ”’ ê°œì„ ëœ ë²¡í„° ê²€ìƒ‰ (ë¸Œëœë“œ > ì¹´í…Œê³ ë¦¬ ìš°ì„ ìˆœìœ„)"""
        try:
            # ğŸ”§ ë¸Œëœë“œì™€ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì¶”ì¶œ
            extracted_brands = self._extract_brands_from_query(query, debug)
            extracted_categories = self._extract_categories_from_query(query, debug)
            
            if debug:
                logger.info(f"ğŸ” ì¶”ì¶œ ê²°ê³¼ - ë¸Œëœë“œ: {extracted_brands}, ì¹´í…Œê³ ë¦¬: {extracted_categories}")
            
            # ğŸ”§ 1ë‹¨ê³„: ë¸Œëœë“œê°€ ìˆìœ¼ë©´ ë¸Œëœë“œ ìš°ì„  (ì¹´í…Œê³ ë¦¬ ë¬´ì‹œ)
            if extracted_brands:
                brand_results = self._try_direct_brand_search(query, top_k, debug)
                if brand_results:
                    logger.info(f"âœ… ë¸Œëœë“œ ìš°ì„  ê²€ìƒ‰ ì„±ê³µ: {len(brand_results)}ê°œ ê²°ê³¼ (ë¸Œëœë“œ: {extracted_brands})")
                    return brand_results
                else:
                    if debug:
                        logger.info(f"âš ï¸ ë¸Œëœë“œ '{extracted_brands}' ì§ì ‘ ê²€ìƒ‰ ì‹¤íŒ¨, ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì§„í–‰...")
            
            # ğŸ”§ 2ë‹¨ê³„: ë¸Œëœë“œê°€ ì—†ê³  ì¹´í…Œê³ ë¦¬ë§Œ ìˆìœ¼ë©´ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰
            elif extracted_categories:
                category_results = self._try_direct_category_search(query, extracted_categories, top_k, debug)
                if category_results:
                    logger.info(f"âœ… ì¹´í…Œê³ ë¦¬ ìš°ì„  ê²€ìƒ‰ ì„±ê³µ: {len(category_results)}ê°œ ê²°ê³¼ (ì¹´í…Œê³ ë¦¬: {extracted_categories})")
                    return category_results
                else:
                    if debug:
                        logger.info(f"âš ï¸ ì¹´í…Œê³ ë¦¬ '{extracted_categories}' ì§ì ‘ ê²€ìƒ‰ ì‹¤íŒ¨, ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì§„í–‰...")
            
            # ğŸ”§ 3ë‹¨ê³„: ë¸Œëœë“œ/ì¹´í…Œê³ ë¦¬ ì§ì ‘ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ë²¡í„° ê²€ìƒ‰
            search_query = query
            
            if debug:
                logger.info(f"ğŸ” ë²¡í„° ê²€ìƒ‰ ì‹œì‘: '{search_query}'")
            
            # ì„ë² ë”© ìƒì„±
            try:
                request_data = {"text": search_query}
                query_vector = self.embedding_executor.execute(request_data)
                
                if not query_vector:
                    logger.info("âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ - í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
                    return self._fallback_text_search(query, filters, top_k, debug)
                    
            except Exception as e:
                logger.info(f"âŒ ì„ë² ë”© API ì˜¤ë¥˜: {e} - í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
                return self._fallback_text_search(query, filters, top_k, debug)
            
            # ë²¡í„° ì •ê·œí™”
            try:
                query_vector_array = np.array(query_vector)
                norm = np.linalg.norm(query_vector_array)
                
                if norm > 0:
                    normalized_query_vector = (query_vector_array / norm).tolist()
                else:
                    normalized_query_vector = query_vector
                    
            except Exception as e:
                print(f"âš ï¸ ë²¡í„° ì •ê·œí™” ì˜¤ë¥˜: {e}")
                normalized_query_vector = query_vector
            
            # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰
            try:
                results = self.collection.query(
                    query_embeddings=[normalized_query_vector],
                    n_results=top_k * 3,
                    include=["metadatas", "distances", "documents"]
                )
                
                if debug:
                    result_count = len(results['ids'][0]) if results and results.get('ids') else 0
                    print(f"ğŸ” ì¼ë°˜ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼: {result_count}ê°œ")
                    
            except Exception as e:
                print(f"âŒ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e} - í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
                return self._fallback_text_search(query, filters, top_k, debug)
            
            # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê²€ìƒ‰
            if not results or not results.get('ids') or not results['ids'][0]:
                print("âŒ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
                return self._fallback_text_search(query, filters, top_k, debug)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_results = []
            ids = results['ids'][0]
            metadatas = results['metadatas'][0] 
            distances = results['distances'][0]
            documents = results['documents'][0]
            
            for i in range(len(ids)):
                formatted_results.append({
                    "id": ids[i],
                    "metadata": metadatas[i],
                    "distance": distances[i],
                    "document": documents[i],
                    "vector_rank": i + 1
                })
            
            print(f"âœ… ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(formatted_results)}ê°œ ê²°ê³¼")
            return formatted_results
            
        except Exception as e:
            print(f"âŒ ë²¡í„° ê²€ìƒ‰ ì „ì²´ ì‹¤íŒ¨: {e} - í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
            return self._fallback_text_search(query, filters, top_k, debug)

    def _apply_personalization_scoring_readonly(self, results: List[Dict], user_profile: Dict, 
                                              parsed_info: Dict, debug: bool) -> List[Dict]:
        """ğŸ”’ ê°œì¸í™” ìŠ¤ì½”ì–´ë§ (ì½ê¸° ì „ìš©)"""
        if not results:
            print("âŒ ê°œì¸í™” ìŠ¤ì½”ì–´ë§: ì…ë ¥ ê²°ê³¼ ì—†ìŒ")
            return []
        
        print(f"ğŸ”„ ê°œì¸í™” ìŠ¤ì½”ì–´ë§: {len(results)}ê°œ ê²°ê³¼")
        
        scored_results = []
        current_date = datetime.now()
        
        # ì „ì²´ ê±°ë¦¬ê°’ ìˆ˜ì§‘ (ìƒëŒ€ì  ê³„ì‚°ìš©)
        all_distances = [result.get('distance', 0) for result in results]
        
        for i, result in enumerate(results):
            try:
                metadata = result.get('metadata', {})
                brand = metadata.get('brand')
                category = metadata.get('category')
                benefit_type = metadata.get('benefit_type')
                discount_rate = float(metadata.get('discount_rate', 0))
                
                # ê¸°ë³¸ ê²€ì¦
                if not self._validate_result(metadata, current_date):
                    continue
                
                # ê°œì¸í™” ì ìˆ˜ ê³„ì‚°
                vector_score = self.calculate_vector_similarity_universal(result.get('distance', 0), all_distances)
                
                # ìµœì¢… ê°œì¸í™” ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í™”)
                personalized_score = vector_score * 0.8 + 0.2  # ë²¡í„° ìœ ì‚¬ë„ 80% + ê¸°ë³¸ ì ìˆ˜ 20%
                
                # ê²°ê³¼ì— ì ìˆ˜ ì €ì¥
                result['personalized_score'] = personalized_score
                result['vector_score'] = vector_score
                
                scored_results.append(result)
                
            except Exception as e:
                if debug:
                    print(f"      âŒ ì˜¤ë¥˜: {e}")
                continue
        
        print(f"âœ… ê°œì¸í™” ìŠ¤ì½”ì–´ë§ ì™„ë£Œ: {len(scored_results)}/{len(results)}ê°œ ì²˜ë¦¬")
        return scored_results
    
    def _validate_result(self, metadata: Dict, current_date: datetime) -> bool:
        """ê²°ê³¼ ìœ íš¨ì„± ê²€ì¦"""
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if not all([metadata.get('brand'), metadata.get('category'), 
                   metadata.get('title'), metadata.get('benefit_type')]):
            return False
        
        # í™œì„± ìƒíƒœ ê²€ì¦
        if not metadata.get('is_active', False):
            return False
        
        # ë‚ ì§œ ìœ íš¨ì„± ê²€ì¦
        if metadata.get('valid_to'):
            try:
                valid_to = datetime.fromisoformat(metadata['valid_to'])
                if valid_to < current_date:
                    return False
            except:
                return False
        
        return True
    
    def _rank_and_select_results(self, results: List[Dict], user_profile: Dict, 
                               top_k: int, debug: bool) -> List[Dict]:
        """ìµœì¢… ìˆœìœ„ ê²°ì • ë° ê²°ê³¼ ì„ íƒ"""
        if not results:
            return []
        
        # ê°œì¸í™” ì ìˆ˜ë¡œ ì •ë ¬
        try:
            sorted_results = sorted(results, key=lambda x: x.get('personalized_score', 0), reverse=True)
        except Exception as e:
            return results[:top_k]
        
        return sorted_results[:top_k]
    
    def _generate_results_readonly(self, results: List[Dict], user_profile: Dict, parsed_info: Dict = None) -> str:
        """ğŸ”’ ê²€ìƒ‰ ê²°ê³¼ ìƒì„± (ì½ê¸° ì „ìš©)"""
        if not results:
            return "âŒ í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” í˜œíƒ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            message = f"ğŸ¯ ê°œì¸í™” í˜œíƒ ì¶”ì²œ ê²°ê³¼:\n\n"
            
            for i, result in enumerate(results[:5], 1):
                metadata = result.get('metadata', {})
                score = result.get('personalized_score', 0)
                
                message += f"**[{i}] {metadata.get('brand', 'Unknown')}** ({metadata.get('category', 'Unknown')})\n"
                message += f"ğŸ¯ {metadata.get('title', 'Unknown')}\n"
                
                # í˜œíƒ ì •ë³´
                benefit_type = metadata.get('benefit_type', 'Unknown')
                discount_rate = metadata.get('discount_rate', 0)
                
                try:
                    discount_rate = float(discount_rate) if discount_rate else 0
                except:
                    discount_rate = 0
                
                if benefit_type == "í• ì¸" and discount_rate > 0:
                    message += f"ğŸ’° {benefit_type}: {discount_rate}% í• ì¸\n"
                elif benefit_type == "ì ë¦½" and discount_rate > 0:
                    message += f"ğŸ’° {benefit_type}: {discount_rate}ë°° ì ë¦½\n"
                else:
                    message += f"ğŸ’° í˜œíƒ: {benefit_type}\n"
                
                conditions = metadata.get('conditions', 'ì¡°ê±´ ì—†ìŒ')
                message += f"ğŸ“ ì¡°ê±´: {conditions}\n"
                
                valid_from = metadata.get('valid_from', 'Unknown')
                valid_to = metadata.get('valid_to', 'Unknown') 
                message += f"ğŸ“… ê¸°ê°„: {valid_from} ~ {valid_to}\n"
                message += f"ğŸ“Š ê°œì¸í™”ì ìˆ˜: {score:.3f}\n\n"
            
            return message.strip()
            
        except Exception as e:
            return f"ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œì˜ í˜œíƒì„ ì°¾ì•˜ì§€ë§Œ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _generate_no_results_message_enhanced(self, parsed_info: Dict, user_profile: Dict, analysis: Dict) -> str:
        """ğŸ” í–¥ìƒëœ ê²°ê³¼ ì—†ìŒ ë©”ì‹œì§€"""
        return "âŒ í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” í˜œíƒ ì •ë³´ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ìŠµë‹ˆë‹¤."

    def _generate_missing_brands_message(self, missing_brands: List[str], context: str) -> str:
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¸Œëœë“œì— ëŒ€í•œ ë©”ì‹œì§€ ìƒì„±"""
        if len(missing_brands) == 1:
            brand = missing_brands[0]
            message = f"âŒ '{brand}' ë¸Œëœë“œëŠ” í˜„ì¬ í˜œíƒ ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
        else:
            brand_list = "', '".join(missing_brands)
            message = f"âŒ '{brand_list}' ë¸Œëœë“œë“¤ì€ í˜„ì¬ í˜œíƒ ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
        
        return message



def chatbot_message():
    """ì±—ë´‡ ë©”ì‹œì§€ ì²˜ë¦¬"""
    rag = initialize_rag_system()
    if not rag:
        return jsonify({
            "success": False,
            "error": "RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        }), 503
    
    
    
    sample_history = create_sample_user_history()
    # rag_system.pyì˜ ë…ë¦½ í•¨ìˆ˜ ì‚¬ìš©
    ra = PersonalizedBenefitRAG()
    user_profile = ra.create_user_profile(sample_history)
    
    
    # ì‚¬ìš©ì í”„ë¡œí•„ ìš”ì•½ ì¶œë ¥
    print(f"   ğŸ“Š ì´ ì†Œë¹„: {user_profile['total_spending']:,.0f}ì› ({user_profile['total_transactions']}ê±´)")
    print(f"   â­ ì„ í˜¸ ë¸Œëœë“œ: {dict(list(sorted(user_profile['brand_counts'].items(), key=lambda x: x[1], reverse=True))[:3])}")
    print(f"   ğŸ·ï¸ ì„ í˜¸ ì¹´í…Œê³ ë¦¬: {dict(user_profile['preferred_categories'][:3])}")
    print(f"   ğŸ“… ìµœê·¼ 1ì£¼ì¼ ì†Œë¹„: {len(user_profile.get('recent_brands', []))}ê±´")
    
    debug_mode = True
    
    # ê¸°ë³¸ ì‘ë‹µ ì´ˆê¸°í™”
    answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    try:
        # ì›¹ ìš”ì²­ì—ì„œ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
        data = request.get_json()
        if not data:
            return jsonify({
                "success": False,
                "error": "ì˜ëª»ëœ JSON í˜•ì‹ì…ë‹ˆë‹¤."
            }), 400
        
        query = data.get('message', '').strip()
        if not query:
            return jsonify({
                "success": False,
                "error": "message íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }), 400
        
        logger.info(f"ğŸ”§ ì§ˆë¬¸: {query}")
        logger.info("â³ ì—°ê²°ëœ RAG + Perplexity ê²€ìƒ‰ ì¤‘...")
        
        # ğŸ”— ê°œì¸í™” í˜œíƒ ê²€ìƒ‰ ë° ì¶”ì²œ (Perplexity ì—°ë™)
        rag_instance = PersonalizedBenefitRAG()
        answer = rag_instance.search_personalized_benefits(query, user_profile, debug=debug_mode)
        
        logger.info(f"ğŸ”— ì¶”ì²œ ê²°ê³¼:\n{answer}")
        
        # ì„±ê³µ ì‘ë‹µ ë°˜í™˜
        return jsonify({
            "success": True,
            "response": {
                "message": answer,
                "timestamp": datetime.now().isoformat(),
                "data": {
                    "total_results": 1,
                    "web_search_used": False,
                    "suggestions": ["ë‹¤ë¥¸ í˜œíƒë„ ì•Œë ¤ì£¼ì„¸ìš”", "ì¹´í…Œê³ ë¦¬ë³„ í˜œíƒ ë³´ê¸°"]
                }
            }
        })

    except Exception as e:
        
        return jsonify({
            "success": False,
            "error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }), 500
